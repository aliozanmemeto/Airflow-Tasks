{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vi6WFTYXSxR"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/real_nvp_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zxKwEBUhf3bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44e32ba-29b2-445d-a27a-74f43a98a2a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Move model on GPU if available\n",
        "enable_cuda = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z191AKvh1KO"
      },
      "source": [
        "This is our target distribution."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiuAXrb0oTFp",
        "outputId": "cc0c8959-4bbd-4a79-ad8a-491e72856c09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.12.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import h5py\n",
        "class TactileMaterialDataset(Dataset):\n",
        "    def __init__(self, file_path, split='train', train_split=0.8):\n",
        "        \"\"\"\n",
        "        Custom Dataset for loading and processing tactile material data.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the HDF5 file.\n",
        "            split (str): Dataset split, either 'train' or 'val'.\n",
        "            train_split (float): Proportion of the dataset to use for training.\n",
        "        \"\"\"\n",
        "        with h5py.File(file_path, 'r') as dataset:\n",
        "            samples = dataset['samples'][:]  # Shape: [materials, samples, time_steps, taxels_x, taxels_y]\n",
        "            materials = dataset['materials'][:]\n",
        "            materials = [m.decode('utf-8') for m in materials]  # Decode material names if necessary\n",
        "\n",
        "        # Set seed for reproducibility\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Shuffle samples within each class\n",
        "        for i in range(samples.shape[0]):\n",
        "            np.random.shuffle(samples[i])\n",
        "\n",
        "        # Splits dataset into train and validation\n",
        "        total_size = samples.shape[1]  # Number of samples per class\n",
        "        train_size = int(train_split * total_size)\n",
        "\n",
        "        # Generate indices for splitting\n",
        "        indices = np.arange(total_size)\n",
        "        np.random.shuffle(indices)\n",
        "        train_indices = indices[:train_size]\n",
        "        val_indices = indices[train_size:]\n",
        "\n",
        "        if split == 'train':\n",
        "            self.data = samples[:, train_indices, ...]  # Training samples\n",
        "            self.labels = np.repeat(np.arange(samples.shape[0]), len(train_indices))  # Class labels\n",
        "        elif split == 'val':\n",
        "            self.data = samples[:, val_indices, ...]  # Validation samples\n",
        "            self.labels = np.repeat(np.arange(samples.shape[0]), len(val_indices))\n",
        "        else:\n",
        "            raise ValueError(\"Invalid split value. Must be 'train' or 'val'.\")\n",
        "\n",
        "        # Flatten the taxels (4x4 -> 16) and reshape to [num_samples, time_steps, features]\n",
        "        self.data = self.data.reshape((-1, samples.shape[2], 16))\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        self.data = torch.tensor(self.data, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
        "        self.labels = torch.tensor(self.labels, dtype=torch.long)\n",
        "\n",
        "        # Debugging\n",
        "        print(f\"{split.capitalize()} dataset size: {len(self.data)}\")\n",
        "        assert len(self.data) == len(self.labels), \"Data and labels length mismatch!\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "train_dataset = TactileMaterialDataset('tactmat.h5', split='train', train_split=0.8)\n",
        "val_dataset = TactileMaterialDataset('tactmat.h5', split='val', train_split=0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TteJJar_nniH",
        "outputId": "fe947ddd-4a8a-41ae-d820-ee446f17f2a8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 2880\n",
            "Val dataset size: 720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "znXZM3xzQ33n"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch-lightning"
      ],
      "metadata": {
        "id": "sbCHmNQZBe5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --quiet \"torchmetrics >=1.0,<1.5\" \"numpy <3.0\" \"torchvision\" \"seaborn\" \"torch >=1.8.1,<2.5\" \"matplotlib\" \"tabulate\" \"pytorch-lightning >=2.0,<2.5\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09lBGrKzu4bv",
        "outputId": "bdb87976-43b8-43ef-d336-6a4a4bad49c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/869.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "import time\n",
        "import urllib.request\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib_inline.backend_inline\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import seaborn as sns\n",
        "import tabulate\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from IPython.display import HTML, display\n",
        "from matplotlib.colors import to_rgb\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "from torch import Tensor\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "tbWSiaK5BknT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageFlow(pl.LightningModule):\n",
        "    def __init__(self, flows, import_samples=8):\n",
        "        \"\"\"ImageFlow.\n",
        "\n",
        "        Args:\n",
        "            flows: A list of flows (each a nn.Module) that should be applied on the images.\n",
        "            import_samples: Number of importance samples to use during testing (see explanation below). Can be changed at any time\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.flows = nn.ModuleList(flows)\n",
        "        self.import_samples = import_samples\n",
        "        # Create prior distribution for final latent space\n",
        "        self.prior = torch.distributions.normal.Normal(loc=0.0, scale=1.0)\n",
        "        # Example input for visualizing the graph\n",
        "        self.example_input_array = train_dataset.data[0][0].unsqueeze(dim=0)\n",
        "\n",
        "    def forward(self, imgs):\n",
        "        # The forward function is only used for visualizing the graph\n",
        "        return self._get_likelihood(imgs)\n",
        "\n",
        "    def encode(self, imgs):\n",
        "        # Given a batch of images, return the latent representation z and ldj of the transformations\n",
        "        z, ldj = imgs, torch.zeros(imgs.shape[0], device=self.device)\n",
        "        for flow in self.flows:\n",
        "            z, ldj = flow(z, ldj, reverse=False)\n",
        "        return z, ldj\n",
        "\n",
        "    def _get_likelihood(self, imgs, return_ll=False):\n",
        "        \"\"\"Given a batch of images, return the likelihood of those.\n",
        "\n",
        "        If return_ll is True, this function returns the log likelihood of the input. Otherwise, the output metric is\n",
        "        bits per dimension (scaled negative log likelihood)\n",
        "\n",
        "        \"\"\"\n",
        "        z, ldj = self.encode(imgs)\n",
        "        log_pz = self.prior.log_prob(z).sum(dim=[1, 2, 3])\n",
        "        log_px = ldj + log_pz\n",
        "        nll = -log_px\n",
        "        # Calculating bits per dimension\n",
        "        bpd = nll * np.log2(np.exp(1)) / np.prod(imgs.shape[1:])\n",
        "        return bpd.mean() if not return_ll else log_px\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, img_shape, z_init=None):\n",
        "        \"\"\"Sample a batch of images from the flow.\"\"\"\n",
        "        # Sample latent representation from prior\n",
        "        if z_init is None:\n",
        "            z = self.prior.sample(sample_shape=img_shape).to(device)\n",
        "        else:\n",
        "            z = z_init.to(device)\n",
        "\n",
        "        # Transform z to x by inverting the flows\n",
        "        ldj = torch.zeros(img_shape[0], device=device)\n",
        "        for flow in reversed(self.flows):\n",
        "            z, ldj = flow(z, ldj, reverse=True)\n",
        "        return z\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
        "        # An scheduler is optional, but can help in flows to get the last bpd improvement\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.99)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Normalizing flows are trained by maximum likelihood => return bpd\n",
        "        loss = self._get_likelihood(batch[0])\n",
        "        self.log(\"train_bpd\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self._get_likelihood(batch[0])\n",
        "        self.log(\"val_bpd\", loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # Perform importance sampling during testing => estimate likelihood M times for each image\n",
        "        samples = []\n",
        "        for _ in range(self.import_samples):\n",
        "            img_ll = self._get_likelihood(batch[0], return_ll=True)\n",
        "            samples.append(img_ll)\n",
        "        img_ll = torch.stack(samples, dim=-1)\n",
        "\n",
        "        # To average the probabilities, we need to go from log-space to exp, and back to log.\n",
        "        # Logsumexp provides us a stable implementation for this\n",
        "        img_ll = torch.logsumexp(img_ll, dim=-1) - np.log(self.import_samples)\n",
        "\n",
        "        # Calculate final bpd\n",
        "        bpd = -img_ll * np.log2(np.exp(1)) / np.prod(batch[0].shape[1:])\n",
        "        bpd = bpd.mean()\n",
        "\n",
        "        self.log(\"test_bpd\", bpd)"
      ],
      "metadata": {
        "id": "7Mzb9VMwFWrr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dequantization(nn.Module):\n",
        "    def __init__(self, alpha=1e-5, quants=155):\n",
        "        \"\"\"Dequantization.\n",
        "\n",
        "        Args:\n",
        "            alpha: small constant that is used to scale the original input.\n",
        "                    Prevents dealing with values very close to 0 and 1 when inverting the sigmoid\n",
        "            quants: Number of possible discrete values (usually 256 for 8-bit image)\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.quants = quants\n",
        "\n",
        "    def forward(self, z, ldj, reverse=False):\n",
        "        if not reverse:\n",
        "            z, ldj = self.dequant(z, ldj)\n",
        "            z, ldj = self.sigmoid(z, ldj, reverse=True)\n",
        "        else:\n",
        "            z, ldj = self.sigmoid(z, ldj, reverse=False)\n",
        "            z = z * self.quants\n",
        "            ldj += np.log(self.quants) * np.prod(z.shape[1:])\n",
        "            z = torch.floor(z).clamp(min=0, max=self.quants - 1).to(torch.int32)\n",
        "        return z, ldj\n",
        "\n",
        "    def sigmoid(self, z, ldj, reverse=False):\n",
        "        # Applies an invertible sigmoid transformation\n",
        "        if not reverse:\n",
        "            ldj += (-z - 2 * F.softplus(-z)).sum(dim=list(range(1, z.ndim)))\n",
        "            z = torch.sigmoid(z)\n",
        "        else:\n",
        "            z = z * (1 - self.alpha) + 0.5 * self.alpha  # Scale to prevent boundaries 0 and 1\n",
        "            ldj += np.log(1 - self.alpha) * np.prod(z.shape[1:])\n",
        "            ldj += (-torch.log(z) - torch.log(1 - z)).sum(dim=list(range(1, z.ndim)))\n",
        "            z = torch.log(z) - torch.log(1 - z)\n",
        "        return z, ldj\n",
        "\n",
        "    def dequant(self, z, ldj):\n",
        "        # Transform discrete values to continuous volumes\n",
        "        z = z.to(torch.float32)\n",
        "        z = z + torch.rand_like(z).detach()\n",
        "        z = z / self.quants\n",
        "        ldj -= np.log(self.quants) * np.prod(z.shape[1:])\n",
        "        return z, ldj"
      ],
      "metadata": {
        "id": "B-yNQDzVGAo9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.data[0][0].unsqueeze(dim=0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r8eShhOJMl1",
        "outputId": "71f8199b-3aea-44d2-acdc-a437f6539a0f"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1000, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing invertibility of dequantization layer\n",
        "pl.seed_everything(42)\n",
        "orig_img = train_dataset.data[0][0].unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "ldj = torch.zeros(\n",
        "    1,\n",
        ")\n",
        "dequant_module = Dequantization()\n",
        "deq_img, ldj = dequant_module(orig_img, ldj, reverse=False)\n",
        "reconst_img, ldj = dequant_module(deq_img, ldj, reverse=True)\n",
        "\n",
        "d1, d2 = torch.where(orig_img.squeeze() != reconst_img.squeeze())\n",
        "if len(d1) != 0:\n",
        "    print(\"Dequantization was not invertible.\")\n",
        "    for i in range(d1.shape[0]):\n",
        "        print(\"Original value:\", orig_img[0, 0, d1[i], d2[i]].item())\n",
        "        print(\"Reconstructed value:\", reconst_img[0, 0, d1[i], d2[i]].item())\n",
        "else:\n",
        "    print(\"Successfully inverted dequantization\")\n",
        "\n",
        "# Layer is not strictly invertible due to float precision constraints\n",
        "# assert (orig_img == reconst_img).all().item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY8Vi39FIwS1",
        "outputId": "738c8ea6-3eb8-4772-9726-3a3044a1b1dc"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dequantization was not invertible.\n",
            "Original value: 0.0\n",
            "Reconstructed value: 1\n",
            "Original value: 17.0\n",
            "Reconstructed value: 18\n",
            "Original value: 0.0\n",
            "Reconstructed value: 1\n",
            "Original value: 8.0\n",
            "Reconstructed value: 9\n",
            "Original value: 0.0\n",
            "Reconstructed value: 1\n",
            "Original value: 3.0\n",
            "Reconstructed value: 4\n",
            "Original value: 14.0\n",
            "Reconstructed value: 15\n",
            "Original value: 10.0\n",
            "Reconstructed value: 11\n",
            "Original value: 0.0\n",
            "Reconstructed value: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_dequantization(quants, prior=None):\n",
        "    \"\"\"Function for visualizing the dequantization values of discrete values in continuous space.\"\"\"\n",
        "    # Prior over discrete values. If not given, a uniform is assumed\n",
        "    if prior is None:\n",
        "        prior = np.ones(quants, dtype=np.float32) / quants\n",
        "    prior = prior / prior.sum()  # Ensure proper categorical distribution\n",
        "\n",
        "    inp = torch.arange(-4, 4, 0.01).view(-1, 1, 1, 1)  # Possible continuous values we want to consider\n",
        "    ldj = torch.zeros(inp.shape[0])\n",
        "    dequant_module = Dequantization(quants=quants)\n",
        "    # Invert dequantization on continuous values to find corresponding discrete value\n",
        "    out, ldj = dequant_module.forward(inp, ldj, reverse=True)\n",
        "    inp, out, prob = inp.squeeze().numpy(), out.squeeze().numpy(), ldj.exp().numpy()\n",
        "    prob = prob * prior[out]  # Probability scaled by categorical prior\n",
        "\n",
        "    # Plot volumes and continuous distribution\n",
        "    sns.set_style(\"white\")\n",
        "    _ = plt.figure(figsize=(6, 3))\n",
        "    x_ticks = []\n",
        "    for v in np.unique(out):\n",
        "        indices = np.where(out == v)\n",
        "        color = to_rgb(\"C%i\" % v)\n",
        "        plt.fill_between(inp[indices], prob[indices], np.zeros(indices[0].shape[0]), color=color + (0.5,), label=str(v))\n",
        "        plt.plot([inp[indices[0][0]]] * 2, [0, prob[indices[0][0]]], color=color)\n",
        "        plt.plot([inp[indices[0][-1]]] * 2, [0, prob[indices[0][-1]]], color=color)\n",
        "        x_ticks.append(inp[indices[0][0]])\n",
        "    x_ticks.append(inp.max())\n",
        "    plt.xticks(x_ticks, [f\"{x:.1f}\" for x in x_ticks])\n",
        "    plt.plot(inp, prob, color=(0.0, 0.0, 0.0))\n",
        "    # Set final plot properties\n",
        "    plt.ylim(0, prob.max() * 1.1)\n",
        "    plt.xlim(inp.min(), inp.max())\n",
        "    plt.xlabel(\"z\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    plt.title(\"Dequantization distribution for %i discrete values\" % quants)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "visualize_dequantization(quants=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "EvBUOjB_JzQf",
        "outputId": "9e9e8484-d2b5-4b99-e5ed-d53d1eb68a8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAE8CAYAAAABlfGWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABz50lEQVR4nO3dd1hUx9fA8S+9izQrdgVUmhobokTE3isWVBQ7GnuLsUbFHsUaxa6xRMVEgzWJGhVLEhVb1NhiB7ELStv3D1/2lw2ogMBd4Hyex0d29u6dc7fcPTszd0ZHpVKpEEIIIYTQUrpKByCEEEII8SGSrAghhBBCq0myIoQQQgitJsmKEEIIIbSaJCtCCCGE0GqSrAghhBBCq0myIoQQQgitJsmKEEIIIbSaJCtCCCGE0GqSrIgc6e7duzg6OrJjx448Ue+HdO3ala5du6pvZ2eMO3bswNHRkbt376rLvL296du3b5bXDXDy5EkcHR05efJkttT3XyEhIdSrV4/y5cvTsmVLRWL4VI6OjixcuFB9O7XXVKSPNp4ncjp9pQMQ77djxw7Gjh2rvm1oaIilpSWOjo54eXnRpk0bzM3NFYww6+3atYvo6Gj8/f3zRL1K2rhxIyYmJrRp00bpUFLQxtiOHj3K7NmzadGiBYMGDcLKyirL6zx+/DhLly7l6tWrJCYmUrJkSfz8/GjVqlWW160NHj16xNatW/Hx8aF8+fJKhyOykSQrOcAXX3yBvb09CQkJPH78mFOnTjF9+nTWrFnDkiVLcHJyUjrELLN7926uXbuWImkoWrQoERER6OtnzVtYqXozQ0Zj3LRpE1ZWVulKCFq2bEnTpk0xNDRMb5jp8r7YqlatSkREBAYGBllaf2pOnDiBrq4u06ZNy/LjB/j5558JDAzE3d2dQYMGoaOjw549exg9ejTPnj3LtMQ6u17TjIiMjGTRokUULVpUkpU8RnvPuEKtTp06uLi4qG/37duX8PBw+vXrx4ABAwgLC8PY2FjBCLOfjo4ORkZGeabe9MiOGGNiYjA1NUVPTw89Pb0sretDdHV1FXs9oqOjMTY2zrQvdZVKxdu3b9/7Wd64cSN2dnasW7dOXaevry+NGzdmx44dmZasZOdrmpSURHx8vNZ/poTyZMxKDlWzZk0GDBjAvXv3+PHHHzXuu379Ol988QXVqlXDxcWFNm3a8PPPP6fYx7Vr1+jWrRuurq7UqVOHJUuWsG3bthT91f/t007m7e3NmDFj1LefPXvGzJkzad68OZUqVaJy5cr06tWLv/76S+NxyeMMwsLCWLp0qToZ6969O7dv31Zv17VrVw4dOsS9e/dwdHTE0dERb29vIGWfcPI+U/uX/BiAgwcP0qdPHzw9PXF2dsbHx4fFixeTmJiYoXqThYeH07lzZ9zd3fnss8/o378/169f19hm4cKFODo6cvv2bcaMGcNnn31GlSpVGDt2LLGxsSme39Rs2bIFHx8fXF1dadeuHb///nuKbVKLMSoqirFjx1KnTh2cnZ3x9PSkf//+6tfZ29uba9eucerUKfUxJ4+DSR7DcOrUKSZNmkTNmjXx8vLSuC+18Q1Hjx6lZcuWuLi40KRJE/bv35/q8/Ff/93nh2J735iVPXv20KZNG1xdXalevTojRozg0aNHGtuMGTOGSpUq8ejRIwYMGEClSpWoUaMGM2fO1Hg/pCb5+Y2JiVHHlPx8JyQksHjxYnx8fHB2dsbb25t58+YRFxensY/ksT2//fabOtbNmze/t85Xr15haWmpkRzp6+tjZWWVph8rcXFxTJ8+nRo1alCpUiX69evHw4cPU2yX2mt6/vx5AgICqF69Oq6urnh7e2t0UcO7xGPt2rU0b94cFxcXatSoQUBAAOfPn9d43qZMmcKPP/5I06ZNcXFx4bfffgPedfGMHTsWDw8PnJ2dadq0Kdu2bVM/9uTJk7Rr1w6AsWPHpnjeAc6dO0dAQABVqlTBzc0NPz8//vjjjw8+L48fP6ZChQosWrQoxX03btzA0dGRDRs2AGk/x6Xmv2PLko0ZM0bjHAXvnss1a9aonyMPDw8mTJjA8+fPNbZLy+uSW0jLSg7WsmVL5s2bx9GjR+nQoQPwLgHp1KkTBQsWpHfv3piamrJnzx4CAwNZuHAh9evXB959eXXr1o3ExET69OmDiYkJW7du/aRfOHfu3OHgwYM0atQIe3t7Hj9+zJYtW/Dz8+Onn36iYMGCGtuvWLECHR0devbsyatXrwgJCWHEiBF8//33APTr14+XL1/y8OFD9QfQzMws1brLlCnDrFmzNMpevnzJjBkzsLa2VpeFhoZiampKjx49MDU15cSJEwQHB/Pq1StGjx6d7nrh3TiC3r17Y29vz8CBA3nz5g0bNmygU6dO7NixA3t7e43thwwZgr29PcOGDePSpUt8//33WFtbM3LkyA8+v99//z0TJkygUqVKdO/enTt37tC/f38sLS0pXLjwBx87aNAg/v77b/z8/ChatChPnjzh2LFjPHjwAHt7e7788ku+/vprTE1N6devHwC2trYa+5g8eTLW1tYEBgYSExPzwfpu3brF0KFD6dixI61bt2b79u0MHjyYkJAQatWq9cHH/ldaYvu35LFeLi4uDBs2jOjoaNatW8eff/7Jzp07yZcvn3rbxMREAgICcHV1ZdSoUYSHh7Nq1SqKFStG586d31vHrFmz2Lp1KxEREUydOhWAypUrA/DVV18RGhpKw4YN6dGjBxEREXz77bdcv36dxYsXa+zn5s2bDB8+HF9fXzp06ECpUqXeW2e1atVYsWIF8+fPp3Xr1ujo6LBr1y4uXLjA/PnzP/o8jhs3jh9//JFmzZpRuXJlTpw4QZ8+fT76uOjoaAICArCysqJPnz7ky5ePu3fvcuDAgRT737FjB3Xq1KFdu3YkJiby+++/c+7cOY2W4RMnTrBnzx66dOmClZUVRYsW5fHjx3To0AEdHR26dOmCtbU1R44cYdy4cbx69Qp/f3/KlCnDF198QXBwML6+vlSpUkXjeQ8PD6d37944OzszcOBAdHR02LFjB927d+e7777D1dU11eOztbWlatWq7Nmzh4EDB2rcFxYWhp6eHo0aNQLSf47LqAkTJhAaGkqbNm3o2rUrd+/eZePGjVy6dIlNmzZhYGCQ5tcl11AJrbV9+3aVg4ODKiIi4r3bVKlSRdWqVSv17e7du6uaNWumevv2rbosKSlJ5evrq2rQoIG6bNq0aSoHBwfVuXPn1GXR0dGqKlWqqBwcHFR37txRlzs4OKiCg4NT1F23bl3V6NGj1bffvn2rSkxM1Njmzp07KmdnZ9WiRYvUZSdOnFA5ODioGjdurBHn2rVrVQ4ODqorV66oy/r06aOqW7duirrv3LmjcnBwUG3fvj3V5yUpKUnVt29flbu7u+ratWvq8tjY2BTbjh8/XuXm5qYRS3rqbdmypapmzZqqp0+fqssuX76scnJyUo0aNUpdFhwcrHJwcFCNHTtWY5+BgYGqatWqpXocyeLi4lQ1a9ZUtWzZUiPOLVu2qBwcHFR+fn7vjfH58+cqBwcHVUhIyAfraNq0qcZ+kiW/Dzt16qRKSEhI9b5/v1/q1q2rcnBwUO3bt09d9vLlS1WtWrU03qvJz8f76vv3Pt8XW/J76cSJEyqV6n/PU7NmzVRv3rxRb/frr7+qHBwcVAsWLFCXjR49WuXg4KDx3lSpVKpWrVqpWrdunfIJ+o/Ro0er3N3dNcouX76scnBwUI0bN06jfMaMGSoHBwdVeHi4uiz5eTpy5MhH61KpVKrXr1+rBg8erHJ0dFQ5ODioHBwcVG5ubqoDBw589LHJcU2aNEmjfNiwYSk+3/99/g8cOPDR81B4eLjKwcFB9fXXX6e4LykpSf23g4ODysnJSeMzqVKpVF9++aWqVq1aqidPnmiUDx06VFWlShX15zYiIiLVz31SUpKqQYMGqp49e2rUFxsbq/L29lb16NHjvbGrVCrV5s2bU5x7VCqVqkmTJqpu3bqpb6f1HJfaecLPzy/V9/Do0aM1zjWnT59WOTg4qH788UeN7Y4cOaJRnpbXJTeRbqAcztTUlNevXwPvmihPnDhB48aNefXqFU+ePOHJkyc8ffoUT09Pbt26pW4KP3z4MO7u7hq/NqytrWnevHmGYzE0NERX991bKjExkadPn2JqakqpUqW4dOlSiu3btGmj0aT92WefAe9+vXyqxYsX8+uvvzJjxgzKli2rLv93c3nyc/TZZ58RGxvLjRs30l1PZGQkly9fpnXr1uTPn19d7uTkhIeHB4cPH07xmI4dO2rc/uyzz3j27BmvXr16bz0XLlwgOjqajh07ajxnrVu3xsLC4oMxGhsbY2BgwKlTp1I0I6dHhw4d0jyWoUCBAupWPABzc3NatWrFpUuXiIqKynAMH5P8PHXq1EmjlfDzzz+ndOnSHDp0KMVjOnXqpHG7SpUqGb5sN/n17tGjh0Z5z549Ne5PZm9vT+3atdO0b0NDQ0qWLEnDhg2ZN28es2fPxtnZmZEjR3L27Nk0xfXfboju3bt/tN7k99ehQ4eIj49PdZv9+/ejo6OTomUC3o2h+reqVatqfCZVKhX79+/H29sblUqlPm89efIET09PXr58ycWLFz8Y4+XLl7l16xbNmzfn6dOn6sfHxMRQs2ZNTp8+TVJS0nsfX79+ffT19QkLC1OXXb16lb///psmTZqoy9J7jsuIvXv3YmFhQa1atTSei4oVK2Jqaqru8kzL65KbSDdQDhcTE4ONjQ0A//zzDyqVigULFrBgwYJUt4+OjqZgwYLcv38fNze3FPd/qBn6Y5KSkli3bh3fffcdd+/e1ej3//cXebIiRYpo3E5unn/x4kWGYwA4cuQIixcvpm/fvjRs2FDjvmvXrjF//nxOnDiRIjl4+fJluuu6f/8+kPrzVqZMGY4ePaoejJrsfcf9/Pnz916KnlxPiRIlNMoNDAwoVqzYB2M0NDRkxIgRzJw5k1q1auHm5sbnn39Oq1atsLOz+8gR/s9/u7M+pESJEim+pEqWLAnAvXv30lVvenzo9ShdunSK8QtGRkYa3YQAlpaWGU7q7t27h66uLsWLF9cot7OzI1++fNy7d0+jPD3P6ZQpUzh37hyhoaHqL8zGjRvTrFkzpk2bpu4+TU9cpUuX/mi91apVo2HDhixatIg1a9ZQrVo1fHx8aN68uTpx/ueffyhQoECqn/P/+u8xP3nyhBcvXrBlyxa2bNmS6mOePHnywX3eunULQN2Vm5qXL19iaWmZ6n3W1tbUqFGDPXv2MGTIEOBdF5C+vr5G0p3ec1xG3L59m5cvX1KzZs1U74+OjgbS9rrkJpKs5GAPHz7k5cuX6hNQ8i+Hnj17vvfX2n9PVp/iv4MQly1bxoIFC2jbti2DBw/G0tISXV1dpk+fjkqlSvH45BPuf6W2bVrduXOHkSNH4uHhoT7pJHvx4gV+fn6Ym5vzxRdfULx4cYyMjLh48SJz5sz54C+vzJQVx/0x/v7+eHt7c/DgQY4ePcqCBQtYvnw5a9eupUKFCmnaR2ZfsfHfZCbZxwa3Zqasuurlfcf2X2m9ii8uLo7t27fTq1cvjfePgYEBtWvXZuPGjcTFxWXJl5SOjg7BwcGcPXuWX3/9ld9++40vv/yS1atXs2XLlg+O50rNf485+XPXokULWrdunepjUhuI/W/Jn51Ro0a995Lmf/9gSE3Tpk0ZO3Ysly9fpnz58uzZs4caNWpoJLPpPcelxX/f70lJSdjY2DBnzpxUt0+OJ7NfF20nyUoO9sMPPwDg6ekJoP6FbWBggIeHxwcfW6RIEY0rb5LdvHkzRZmlpWWK1o64uLgUzfn79u2jevXqTJ8+XaP8xYsXGZ4wK60nfYA3b94waNAgLCwsmDdvXoqk4NSpUzx79oxFixZRtWpVdXlqTf5prTe5lSS15+3GjRtYWVl99CSZnnpu376t8YsrPj6eu3fvpmmuneLFi9OzZ0969uzJrVu3aNWqFatWrVKfFNPzXH/M7du3UalUGvtM/vVbtGhRQLMl7d+DXpNbR/4tI6/Hf3+Z3rx5M0WrVmYrWrQoSUlJ3L59mzJlyqjLHz9+zIsXL9THnl7Pnj0jISEh1UQuISGBpKSkDybbyXH9888/Gq0p6en6dHd3x93dnaFDh7Jr1y5GjBhBWFgY7du3p3jx4hw9epRnz56lu4XB2toaMzMzkpKSPnreet/7IPncZ25u/tF9vI+Pjw8TJkxQdwXdunUrxUzMn3KOs7S0TLWL+7/v9+LFixMeHk7lypXTlMx+6HXJTWTMSg4VHh7OkiVLsLe3p0WLFgDY2NhQrVo1tmzZQmRkZIrH/Lsp1cvLi7NnzxIREaFx/65du1I8rlixYikukd26dWuKE6eenl6KXxd79uxJccloepiYmKS5e2bixIncunWLRYsWpdrcm5y8/DvGuLg4vvvuuwzXW6BAAcqXL8/OnTs1ErqrV69y7Ngx9SW+n8rZ2Rlra2s2b96scQlsaGjoR7vNYmNjefv2rUZZ8eLFMTMz09iXiYnJJ3fBJYuMjNS4KuHVq1fs3LmT8uXLq7uAklv5Tp8+rd4uJiaGnTt3pthfWmNzdnbGxsYmxfN0+PBhrl+/zueff57BI0qb5Nd77dq1GuWrV6/WuD+9bGxsyJcvHwcOHNA4rtevX/Prr79SunTpD36x1alTB4D169drlP83ztQ8f/48xec6ufUiOZYGDRqgUqlSvfz3Yy0Oenp6NGzYkH379nH16tUU9//7vGViYgKk7Cp2dnamePHirFq1Sj2G7337eJ98+fLh6enJnj17+OmnnzAwMMDHxydFrBk9xxUrVowbN25oxPLXX3/x559/amzXuHFjEhMTWbJkSYp9JCQkqI89La9LbiItKznAkSNHuHHjBomJiTx+/JiTJ09y7NgxihQpwtKlSzWa5ydOnEjnzp1p3rw5HTp0oFixYjx+/JizZ8/y8OFD9ZwsvXr14ocffqBXr15069ZNfelykSJFuHLlikb97du3Z+LEiQwaNAgPDw/++usvjh49muKXxOeff87ixYsZO3YslSpV4urVq+zateujYyo+pGLFioSFhREUFISLiwumpqYp5iSAd4PMdu7cScOGDbly5YrGMZiZmeHj40OlSpWwtLRkzJgxdO3aFR0dHX744YdUT6ZprRfeNT337t0bX19f2rVrp7502cLCItUBhxlhYGDAkCFDmDBhAt27d6dJkybcvXuXHTt2fPT5vXXrFv7+/jRq1IiyZcuip6fHwYMHefz4MU2bNtU45k2bNrFkyRJKlCiBtbX1e/vNP6ZkyZKMGzeO8+fPY2Njw/bt24mOjiYoKEi9Ta1atShSpAjjxo3jxo0b6OnpsX37dqysrFL82kxrbAYGBowYMYKxY8fi5+dH06ZN1ZcuFy1aNMuXT3BycqJ169Zs2bKFFy9eULVqVc6fP09oaCg+Pj7UqFEjQ/vV09OjZ8+ezJ8/H19fX1q2bElSUhLbtm3j4cOHzJ49+4OPL1++PM2aNeO7777j5cuXVKpUiRMnTqTauvpfoaGhbNq0CR8fH4oXL87r16/ZunUr5ubm6iSoRo0atGzZkvXr13P79m1q165NUlISf/zxB9WrV8fPz++DdQwfPpyTJ0/SoUMH2rdvT9myZXn+/DkXL14kPDycU6dOAe8S3Hz58rF582bMzMwwNTXF1dWVYsWKMXXqVHr37k2zZs1o06YNBQsW5NGjR5w8eRJzc3OWLVv20WNt0qQJI0eO5LvvvsPT01OjxQ8+7RzXrl071qxZQ0BAAO3atSM6OprNmzdTtmxZjQSrWrVq+Pr68u2333L58mVq1aqFgYEBt27dYu/evYwbN45GjRql6XXJTSRZyQGCg4OBdyfi/Pnz4+DgwJdffpnq2kBly5Zl+/btLFq0iNDQUJ49e4a1tTUVKlQgMDBQvV2BAgVYt24dU6dOZfny5eTPn5+OHTtSoEABxo0bp7HPDh06cPfuXbZt28Zvv/1GlSpVWL16dYoTf79+/YiNjWXXrl2EhYVRoUIFvv32W+bOnZvhY+/cuTOXL19mx44drFmzhqJFi6aaNCT/Wtm3bx/79u3TuK9o0aL4+PhgZWXFsmXLmDlzJvPnzydfvny0aNGCmjVrEhAQkKF6ATw8PAgJCSE4OJjg4GD09fWpWrUqI0eO/KRE7b98fX1JTExk5cqVzJo1CwcHB5YuXfrewdTJChUqRNOmTQkPD+fHH39ET0+P0qVLM3/+fI0ByIGBgdy/f5+QkBBev35NtWrVPilZGT9+PLNmzeLmzZvY29vzzTffaIylMjAwYNGiRUyePJkFCxZgZ2dH9+7dyZcvX4qJrdITW5s2bTA2NmbFihXMmTMHU1NTfHx8GDlyZIovn6wwdepU7O3tCQ0N5eDBg9ja2tK3b99PTlz79++Pvb0969atY/HixcTFxeHo6EhwcHCKgeSpmT59OlZWVuzatYuff/6Z6tWrs3z58o+29lSrVo3z588TFhbG48ePsbCwwNXVlTlz5mi8v4OCgnB0dGTbtm3MmjULCwsLnJ2dqVSp0kdjs7W15fvvv2fx4sUcOHCATZs2kT9/fsqWLcuIESPU2xkYGDBjxgzmzZvHpEmTSEhIICgoiGLFilG9enW2bNnCkiVL2LBhAzExMdjZ2eHq6oqvr+9HY4B3E/UZGxvz+vVrjauAkn3KOa5MmTLMnDmT4OBggoKCKFu2LLNmzWL37t3qZCzZlClTcHZ2ZvPmzXzzzTfo6elRtGhRWrRooZ5XJq2vS26ho8rKUX0ix0meUOvnn39O15UKQgghRFaRMStCCCGE0GqSrAghhBBCq0myIoQQQgitJmNWhBBCCKHVpGVFCCGEEFpNkhUhhBBCaDWZZyUVSUlJREZGYmZmlqlTkAshhBC5nUql4vXr1xQoUOC9a6GllyQrqYiMjMy0adKFEEKIvOjw4cMUKlQoU/YlyUoqklerPHz4cIoZYoUQQgjxfq9evcLLyytTV36WZCUVyV0/5ubmkqwIIYQQGZCZwyhkgK0QQgghtJokK0IIIYTQapKsCCGEEEKryZgVIYQQIhOpVCoSEhJITExUOpQsoaenh76+frZO7SHJihBCCJFJ4uLiePDgATExMUqHkqVMTU0pXLgwhoaG2VKfJCtCCCFEJkhKSuLmzZvo6elRpEgRDA0Nc93EoiqViri4OKKiorh58yblypXLtInfPkSSFSGEECITxMXFkZSURLFixTA1NVU6nCxjYmKCgYEBt2/fJi4uDmNj4yyvUwbYCiGEEJkoO1oalJbdx5j7n1EhhBBC5GiSrAghhBBCq8mYFSGEECKLvXgTz5u47LuU2dhQj3zGBtlWX1aTZEUIIYTIQi/exLPw52s8eR2XbXVamxkyqF65dCcsGzduZOXKlURFReHk5MT48eNxdXXNoijTTpIVIYQQIgu9iUvkyes4jPT1MDXUy/L6Yv6/vjdxielKVsLCwggKCmLy5Mm4ubmxdu1aAgIC2Lt3LzY2NlkY8cdJsiKEEEJkA1NDPcyMsudr921C+rucVq9eTYcOHWjbti0AkydP5tChQ2zfvp0+ffpkdojpohUDbDdu3Ii3tzcuLi60b9+eiIiI9267detWOnfuTNWqValatSr+/v4pth8zZgyOjo4a/wICArL6MIQQQogcKS4ujosXL+Lh4aEu09XVxcPDgzNnzigY2TuKt6ykt9np5MmTNG3alMqVK2NoaEhISAg9e/bkp59+omDBgurtateuTVBQkPp2dk0JLIQQQuQ0T58+JTExMcX3ro2NDTdu3FAoqv9RPFlJb7PT3LlzNW5PnTqVffv2ER4eTqtWrdTlhoaG2NnZZWnsQojsERMTw8OHD4mKiiI6OprExET09PQwMDDAzs6OIkWKYGtrmycm4xIiL1I0WUludurbt6+6LL3NTrGxsSQkJGBpaalRfurUKWrWrEm+fPmoUaMGQ4YMwcrKKlPjF0Jkvjdv3nD8+HEOHTrE2bNnuXDhAjdv3vzo4wwNDSlfvgKVKrlTqVIl6tWrR4UKFXLd2ixCZAUrKyv09PSIjo7WKI+OjsbW1lahqP5H0WQlM5qd5syZQ4ECBTT62WrXrk39+vWxt7fnzp07zJs3j969e7Nlyxb09LJ+JLYQIn2ePXtGaGgoW7Zs4dChQ7x9+zbFNkb6+tgYG2MZn8DrfCVQqZLQNVTx/OUTnr96SlxcHOfOneXcubOsWbMGgKJFitKocSM6d+7M559/Li0vQryHoaEhFStWJDw8HB8fH+Ddwozh4eH4+fkpHJ0WdAN9iuXLlxMWFsa6deswMjJSlzdt2lT9d/IAWx8fH3VrixBCeSqViqNHj7Jw4UJ++OEH4uL+NwdFQTMzPIoWpXLhIjgVLYpTsWLYWlmho6tL1Or1HK7zDQCVGhRDT1+XuLdxPIi8z9Xrf3HtxiUuXjvL+Wt/cO/+PVauXMnKlSspWqQoXbt1JTAwEHt7e6UOW+RhMdk0KVxG6+nRowejR4/G2dkZV1dX1q5dS2xsLG3atMnkCNNP0WTlU5qdVq5cyfLly1m9ejVOTk4f3LZYsWJYWVlx+/ZtSVaEUFhiYiJbtmxhzpw5Gt29DtbWtCjnQFNXV5zKlkXX2DhFF44qPj7F/nR0dDAyNqJk8VKULF6KBnUbAxD7Jpbfz5zgl+P7OHJqL/fu32PGjBnMmTOH9u07MGrUSNzd3bP0WIWAd7PJWpsZ8uR1XIYuKc4IazNDjNM5p0uTJk148uQJwcHBREVFUb58eUJCQqQbKKPNTitWrGDZsmWsXLkSFxeXj9bz8OFDnj17JgNuhVBQUlISoaGhTJgwgUuXLgFgrK9PawcH/KtVx7VCBfQycal5E2MTatesS+2adXnzdhKHjh1gW9gGzl/9nU2bvmPTpu9o17Y904OmUa5cuUyrV4j/ymdswKB65XLEdPt+fn5a0e3zX4p3A32s2WnUqFEULFiQ4cOHA++6foKDg5k7dy5FixYlKioKAFNTU8zMzHj9+jWLFi2iYcOG2NracufOHWbPnk2JEiWoXbu2YscpRF72+++/ExgYyKlTpwDIb2xMbzd3uteujZ29PTpZPJbE2MiYRt7NaeTdnAt/nWP9tuUcPr2Pbdu/J3TnDnr16s306dOwtrbO0jhE3pXP2CBXrdWT3RRPVj7W7PTgwQONQXGbN28mPj6eL774QmM/AwcOZNCgQejp6XH16lV27tzJy5cvKVCgALVq1WLw4MEy14oQ2Sw6Opovv/ySFStWoFKpMDM0pJerG/3qeWNdpKgiV+o4O7kx86vFXL1+iYWrZ3Eq4je+/XYZ27ZtY+6cOXTr3k2uIBJCy+ioVCqV0kFom1evXlGlShX++OMPzM3NlQ5HiBxp9+7d9OrVi0ePHgHQ2sGR8Y0aUbR06Qy3pKji44kMWaMxwFbf4NOu8Dt9NpxZSyfyz4PrANSp/Tnr1q+hRIkSn7Rfkfe8efOGmzdvUqpUKYwzsUtTG33oWLPiO1Su4xNCZKoXL17Qq1cvmjdvzqNHjyhnbc229h1Y1rcv9mXLZnmXT3pVda/Jd4t207fzcIwMjDny2yFcnF1YvXoN8ltOCO2gXWcNIUSOdvr0adzc3Fi5ciU6Ojr0cXdn/8BB1KldGx0D7e2vNzAwpGfHAWxYuJsKZdx4+eolPXv2oF3b9rx48ULp8ITI8yRZEUJ8MpVKxbJly/D09OTWrVsUt7Rka9t2fN3dHzMtuOwxrYoXKcWKOVvp3XEoerr67AjdTuVKVbhw4YLSoQmRp0myIoT4JDExMXTv3p3+/fsTFxdHo9Kl2d+vP1516qCTA2eM1tfTp1fngSwL2oStVUGu3/ibalWrs2HDBqVDEyLPkmRFCJFhd+/exdPTk/Xr16Onq8s4Dw9W9+mLddGiSof2yVzLV2ZD8C6qVKxJ7JsYunbtyvBhI0hMzL65MoQQ7yh+6bIQImc6c+YMDTyq8/hNPDampixt3Bgvz9o5sjXlfawsbVg4dS1L181lfei3zPtmLr+F/cihP89iamqqdHgiJ3nzHOJjs68+AxMwtvz4djmEJCtCiHQLCwvD17cDr97EU9rQkOUdWuNSqXqunJ9ET0+P/l1HwFMLvjsyl9NXrlGrZg327j9AwYIFlQ5P5ARvnsPhWRAT/fFtM4upDXiNyjUJiyQrQoh0Wbt2LT179iQpKYnqpqYsKFIUW/tiuTJR+bdqDj6Y6xxl7bE/OBtxnmqffcavhw9TunRppUMT2i4+9l2iom8CBtnQIhcf866++Ng0JyunT59m5cqVXLhwgaioKBYvXqxeBkcbyJgVIUSaLVq0CH9/f5KSkihfz4Fv7YuRLxd1+3xMGTsbBtXzoKBVfv65e5eaNarLlUIi7QxMwcg86/9lICGKiYnB0dGRiRMnZsGBfzpJVoQQH6VSqZg2bRqDBg0CwL2tO92+6oRhLm9NSY2dhTnfjB1BySKFiYx6TO1atTh18qTSYQnxSby8vBg6dCj169dXOpRUSbIihPgglUrFmDFj+OqrrwCo1q0aXcd0xdwg7y5FYZPfkqVTJ+JUqiTPXrygrnddjhw5rHRYQuRakqwIId5LpVIxYsQIZs2aBYBnX086fdEJY/3cve5JWuQzN2fh5K9wd3IgJiaWxo0ac+zYUaXDEiJXkmRFCJEqlUrFuHHjmDdvHgB1h9SlXe92GOrJ6uXJTI2NmffVGCo5ORITG0vDBg0JDz+udFhC5DqSrAghUjVlyhSCgoIA8PrCi5ZdW2Kgp73r+yjFyNCQOeNG4ebowOuYGBo2aMCpUzKGRYjMJMmKECKFoKAgJk2aBEDt/rVp3a01BrqSqLyPsZERc8aNwrlcGV6+ek19Hx/OnjmjdFhC5Boyz4oQQsPixYv58ssvAfDo5UHbgLbSopIGyV1CQ6YEcen6Der7+BB+8iRly5ZVOjShLeJjtLae169f888//6hv3717l8uXL2NpaUmRIkUyM7oMkWRFCKH2/fffqy9PrtatGu36tZNEJR3MTEz4ZvwY+n81mRt371Gv7uecOHWawoULKx2aUJKBybsZZWOiISGbptw3tXlXbxpduHCBbt26qW8ndwG3bt2aGTNmZHp46SXJihACgF9//RU/Pz9UKhWuLV3pMLADRnpGSoeV45ibmjJ/wlj6fjmRf+7ew6duXY6dOEH+/PmVDk0oxdjy3dT3Wrw2UPXq1bly5UoWBvRpJFkRQnD27FlatmxJXFwcZeuUpcuYLpik41eZ0GSTPz/zJ3xJv3GTuHTlCo0b1OeXw0cwMZHnNM8ytsw16/QoQQbYCpHH3bhxg8aNG/Py5Uvs3ezpNrUb5sZ5d8K3zGJfqCDzvhqNqbERJ07/jm+7diQlJSkdlhA5kiQrQuRh0dHRNGrUiIcPH2JXxo7uc7pjY2GjdFi5hkOpkswcPRx9PT12hYUxYugQpUMSIkeSZEWIPCouLo62bdty7do1LAtZ0mVuF4rYKj/qP7epXLECY/r1AuCb4IUsWbhQ4YiEyHkkWREiD1KpVPTt25fDhw9jZGpE2xltKVtcLrHNKo29atOjbSsAvhgyhD1hPykbkBA5jCQrQuRBs2bNYs2aNejo6tBkYhMqu1ZGJw+uoJydAjq0pX6tGiQmJdGhQwciIs4pHZIQOYYkK0LkMTt27GDMmDEA1BlYh7o+dSVRyQY6Ojp8OaAvro7lePU6hsYN340VEkJ8nCQrQuQhf/zxB35+fgC4tnKlZbeW6OnqKRxV3mFoYMDM0cOxL1iA+w8f0rJZM+Li4pQOSwitJ/OsCJFHPHr0iJYtWxIbG0uJaiXoOKqjTPqmgHzm5swaO4JeYyZw6o8/6Ne7F6vWrlM6LJHFXsa95E3Cm2yrz1jfGAtDi2yrL6tJsiJEHhAfH0/79u25d+8e1sWt6TK1C5YmMkGVUkoUKcKkwYGMnjWP1evW4+5eiS+GDlU6LJFFXsa95NuIb3n65mm21WllbEVf1765JmGRZEWIPGDYsGH89ttvGJka0W5aO4raFVU6pDyvVpVK9O7QluVbtjFs5Ehc3dz43Ntb6bBEFniT8Ianb55irGeMsb5xttX3JuFNmpOVb7/9lv3793Pjxg2MjY2pVKkSI0aMoHTp0lkcbdpIsiJELrdmzRoWLVoEQMOxDXGt6KpwRCJZtzYtuXbrNr+ePE3btm358+xZSpQooXRYIosY6xtjZmCWLXW9SUxfl9OpU6fo0qULLi4uJCYmMm/ePAICAvjpp58wNTXNoijTTpIVIXKx06dP069fPwCqd69OvSb15MofLaKjo8O4wL78c/8B1+/cpVnjxpz8/Xet+HIQecvKlSs1bs+YMYOaNWty8eJFqlatqlBU/6MVVwNt3LgRb29vXFxcaN++PREREe/dduvWrXTu3JmqVatStWpV/P39U2yvUqlYsGABnp6euLq64u/vz61bt7L4KITQLo8ePaJNmza8ffuW0h6ladO/Dfq68vtE25gYGzNz9HDymZtx4fJlAvy7o1KplA5L5HEvX74EwNJSO8a2KZ6shIWFERQURGBgIKGhoTg5OREQEEB0dHSq2588eZKmTZuybt06Nm/eTOHChenZsyePHj1Sb7NixQrWr1/PpEmT2Lp1KyYmJgQEBPD27dvsOiwhFBUfH0+HDh24e/cu1sWt6TSlE+ZGsjihtipcwI6pQ79AV0eHzd9vY8kimZJfKCcpKYnp06dTuXJlHBwclA4H0IJkZfXq1XTo0IG2bdtStmxZJk+ejLGxMdu3b091+7lz59KlSxfKly9PmTJlmDp1KklJSYSHhwPvWlXWrVtH//798fHxwcnJiVmzZhEZGcnBgwez89CEUMzo0aM5cuTIu6n0p7WliI2s+aPtqrhUpE/H9gAMHTackydOKByRyKsmT57MtWvX+Oabb5QORU3RZCUuLo6LFy/i4eGhLtPV1cXDw4MzZ86kaR+xsbEkJCSom6ru3r1LVFSUxj4tLCxwc3NL8z6FyMl27NihPsk0GNsAt4puCkck0sqvVXNqVXYnPiGBNq1bv7eFWYisMmXKFA4dOsTatWspVKiQ0uGoKZqsPH36lMTERGxsNJekt7Gx4fHjx2nax5w5cyhQoIA6OYmKilLvI6P7FCKn+vvvv+nRowcAlTtUpl5jGVCbk+jo6DB+UH+K2Nly/+FDOrRtQ1JSktJhiTxApVIxZcoUDhw4wNq1aylWrJjSIWnI0aPtli9fTlhYGOvWrcPISGbiFHlbbGws7du358WLFxR1KUq7we0w0DNQOiyRThZmZkwbOZS+4ybyy+EjTBg3jqlBQUqHJTJBds1gm5F6Jk+ezO7du1myZAlmZmbqH/4WFhYYG2f93DAfo2iyYmVlhZ6eXoqmzujoaGxtbT/42JUrV7J8+XJWr16Nk5OTutzOzk69jwIFCmjs89/bCZHbDBkyhLNnz2Ka35R2U9phaaodo/hF+jmULMGIXj2YvnQF02fOpJanJ42bNlU6LJFBxvrGWBlbvZuoLZ3zn2SUlbFVuiag27RpEwBdu3bVKA8KCqJNmzaZGltGKJqsGBoaUrFiRcLDw/Hx8QFQD5ZNXmwtNStWrGDZsmWsXLkSFxcXjfvs7e2xs7MjPDyc8uXLA/Dq1SvOnTtHp06dsu5ghFDQhg0bWL58OTo6OjT+qjHlSpRTOiTxiZrW9SLiryvs/vUInTt3JuLCBa1rmhdpY2FoQV/Xvlq9NtCVK1eyMJpPp3g3UI8ePRg9ejTOzs64urqydu1aYmNj1ZncqFGjKFiwIMOHDwfedf0EBwczd+5cihYtqm6qMjU1xczMDB0dHbp168bSpUspUaIE9vb2LFiwgAIFCqgTIiFyk4sXL9K3b18AqnatilddLxmnkksMC/Dnyo2bXLt9h7atWnH85En09RU/bYsMsDC0yDXr9ChB8Xd9kyZNePLkCcHBwURFRVG+fHlCQkLU3UAPHjxAV/d/44A3b95MfHw8X3zxhcZ+Bg4cyKBBgwDo3bs3sbGxTJgwgRcvXlClShVCQkJkXIvIdV69ekX79u2JiYmheJXitO3fFj1dPaXDEpnEyNCQqcOH4D/qS07/+SdjR45kthZdTipEdlE8WQHw8/N7b7fP+vXrNW7/8ssvH92fjo4OgwcPZvDgwZkSnxDaSKVS0bdvXy5fvoy5rTkdJnfA3Fgmfstt7AsVZEy/3kycv4i5Cxbg7eMj41dEnqP4pHBCiIwJCQnhu+++Q1dPl6bjm1KySEmlQxJZxMejBi28P0elUuHX1Y8HDx4oHZIQ2UqSFSFyoAvnz6u7Qmv0qEEtz1oyTiWXG9KzG6Xsi/Lk6TPatW5FQkKC0iEJkW0kWREih4l5/RrPxtV48+YNJaqWoGWvljJOJQ8wMjRk6rAvMNTX4/jJU4xrNUgWPBR5hiQrQuQwg4cM5Pm9N+jn06fpyHqyQGEeUqxQQdpVfrd8wpyw5Rza9/ExfELkBpKsCJGDbN++nZCQNQAU7VMUC2tJVPKaqqWK0865EUmqJLp09SMyMlLpkITIclpxNZAQ4uNu375Nr169ALBtYouFs8zZkFdNrT+Es/cv8ffjf+jm60fYz3s1pngQ2ifx5UuSYmOzrT5dExP0LHLPOUKSFSFygISEBLp06cKzZ8+oWtaGmDYFlQ5JKMjM0JQlLSfTYkM/9h06wJzpsxj11RilwxLvkfjyJY+XLCXh6dNsq1PfygrbAf1zTcIiyYoQOcDkyZM5duwY+UwNWTPEG1/9y0qHJBRWvkAZpvf5imGLxzNu0ng+r1eXajWrKx2WSEVSbCwJT5+ia2SErolJttWXFBub5mTlu+++Y9OmTdy7dw+AcuXKMWDAALy8vLIy1DSTZEUILffrr78ybdo0AJb3qkbJsg7wUJIVAd0bd+LQ2WP8eGwvnXw7cvZiBBa55Jd0bqRrYoKumVm21JX09m26ti9UqBAjRoygRIkSqFQqdu7cSWBgIKGhoZQrp/xaY9LJKYQWe/z4MX5+fqhUKgLqlsa3WT2Q+VTE/9PR0SF42EyK2hbmxp1bDAjop3RIIofy9vbGy8uLkiVLUqpUKYYOHYqpqSlnz55VOjRAkhUhtJZKpaJHjx7cv38fp6KWLAhsBvqyvpXQlN/CkuVj5qOro8uG779jw+p1SockcrjExER++uknYmJiqFSpktLhAJKsCKG1goOD2b17N0YGemwZ6o2ZdSGlQxJaqpZrdUZ0HgjAgIGBXP/7usIRiZzoypUrVKpUCRcXFyZOnMjixYspW7as0mEBGUxWTpw4kdlxCCH+5cyZM4waNQqAuX6VcK1UReGIhLYb5fcF1ctX4WXMKzq18yU+Pl7pkEQOU6pUKXbu3MnWrVvp1KkTo0eP5u+//1Y6LCCDyUqvXr3w8fFhyZIlsqCWEJns1atX+Pr6EhcXR6uqxRjg2wh0pBFUfJi+nj4rvlxAPlMLTp/7gwmjxykdkshhDA0NKVGiBM7OzgwfPhwnJyfWrdOObsUMnQGPHDmCn58f+/btw8fHh4CAAMLCwoiLi8vs+ITIcwYOHMi1a9ewtzFj5ZAm6BiaKh2SyCGKF7Rn/pDpAMycP4ef9x9UOCKRkyUlJWnN93qGLl22trbG398ff39/Ll68yI4dO5g8eTKTJ0+mefPmtGvXDicnp8yOVYhcb9OmTaxduxZdXR2+G1Qb60LFlQ5J5DBtPm/OL78fYcP+7+nWtRvnLkZga2urdFgCsm0G24zUM3fuXOrUqUPhwoV5/fo1u3fv5tSpU6xcuTILIky/T55npWLFitja2pI/f36WL1/O9u3b+e6773B3d2fy5MlacX22EDnBjRs36Nfv3aWn41tVpLanh1ymLDJkZuBkTlz4nb/v36RnF39+2LsLHXkvKUbXxAR9K6t3E7Wlc/6TjNK3skrXBHTR0dGMHj2ayMhILCwscHR0ZOXKldSqVSsLo0y7DCcr8fHx/Pzzz2zfvp3jx4/j7OzMhAkTaNq0KU+ePGH+/PkMHjyYsLCwzIxXiFwpPj6ezp078+LFC2o5FuCrHo1BV+ZsFBljZmJKyLiF1P+iNbv2/8SS+YsIHDpI6bDyLD0LC2wH9NfqtYGmT5+ehdF8ugydDb/++mt2794NQIsWLRg5ciQODg7q+01NTRk9ejS1a9fOnCiFyOUmTZrEyZMnsTQzZOPQ+uibWSkdksjh3Ms5M7HnKL5aMY0RY0ZSx9sLFzdXpcPKs/QsLHLNOj1KyFCy8vfffzN+/HgaNGiAoaFhqttYWVlpzShiIbTZr7/+SlBQEAArelWjRLkKCkckcosBbQP45Y8j/PLnb3Rq35HT5/7AJBvWphEis2XoaqCBAwfSqFGjFIlKQkICp0+fBkBfX59q1ap9eoRC5GLR0dF07dr1/6fTL0P7pt4yTkVkGl1dXZaNnoedpQ0Xr11m+MChSockRIZkKFnp1q0bz58/T1H+8uVLunXr9slBCZEXqFQqAgICuHfvHo5FLFkwoDHoGysdlshlCljZsWTkXACWrvqWndtDFY5IiPTLULKiUqlSHVn+7NkzaWIUIo2WLVvGDz/8gKGBHpuGeGFmU0TpkEQuVb/a5wS2CQAgICCAu3fvKhyREOmTrjErAwe+W3tCR0eHMWPGaHQDJSYmqtcVEEJ82IULFxg2bBgAMzq6UqlyVYUjErndhJ6j+O1sOBE3LtHVtwsHj/yCnp6e0mEJkSbpalmxsLDAwsIClUqFmZmZ+raFhQV2dnb4+voye/bsrIpViFwhNjaWTp068ebNGxq5F2Fwx0agK18aImsZGRqxctxCTI1MOHT8CDOmaPelqkL8W7paVpKvWChatCg9e/bE1FSmARcivUaOHMmFCxcomN+UNYMboGsilzOK7FGuWBlmBk5i0LzRTJw6Ge/69ajp6aF0WEJ8VIYuXU7uDhJCpM+PP/7I4sWLAVjbvwYFi8sMzyJ7+TXswC+/HyH0yE906tiJsxfOkT9/fqXDyvXexiaQEJeYbfXpG+phZJJ7JpZM85G0bt2aNWvWYGlpSatWrT44dXNoqIw2F+K/7t27R8+ePQEY1sSJht515DJlke10dHSYPzSIP/46x+17/9DHvxdbQr+X6fiz0NvYBH7/6Saxr+KzrU4TcwM+a1oq1yQsaT6KevXqqQfU+vj4ZFlAQuRGiYmJdOvWjejoaCqVsmF670agl/qEikJkNUuzfIR8GUzjYe35/oft1F+2gt79+ygdVq6VEJdI7Kt49A100TfM0EW46awvidhX8STEJWYoWVm+fDlz586lW7dujBs3LgsiTL80H8W/u36kG0iI9Jk9eza//PILpkYGbBr8OUaWBZQOSeRx1SpUZlz34UxZPYvBQwdTq44nFSrK7MlZSd9QF0Pj7GjpSCAhPilDj4yIiGDz5s04OjpmckyfJutTPCHyuFOnTjF+/HgAFnavjKOLXN4vtMMQ3354udUi9u0bOrbtwJs3b5QOSSjo9evXjBw5kqlTp2Jpaal0OBrSnOJVrVo1zX2ap06dSnMAGzduZOXKlURFReHk5MT48eNxdU19sa1r164RHBzMxYsXuXfvHmPHjsXf319jm4ULF7Jo0SKNslKlSrF37940xyREZnnx4gWdOnUiISGBDjVK0KOND+jIbwShHXR1dfl2zDd49m3E+SsXGT5oKItXLFU6LKGQKVOm4OXlhYeHB0uXatf7IM3JypdffpnplYeFhREUFMTkyZNxc3Nj7dq1BAQEsHfvXmxsbFJsHxsbi729PY0aNVJfRp2acuXKsXr1avVtmfhIKCUwMJAbN25Qws6Cbwc1QsfQTOmQhNBQyKYAS0bNpcNXPVgSsgyfhg1o3a610mGJbPbTTz9x6dIltm3bpnQoqUrX1UCZbfXq1XTo0IG2bdsCMHnyZA4dOsT27dvp0yflYC9XV1d1q8vcuXPfu189PT3s7OwyPV4h0mPDhg1s2LABXV0dNg70JH+h4kqHJESqGlSrS2DrABaHrqRXrwA+q/4ZxYoVUzoskU0ePHjAtGnTWLVqFUZGRkqHk6o0JyuvXr3C3Nxc/feHJG/3IXFxcVy8eJG+ffuqy3R1dfHw8ODMmTNpDStVt2/fxtPTEyMjI9zd3Rk+fDhFisi6KyL7XLt2jf79+wMwsY0ztWrVlMuUhVabEDCKo+dOcO7GRfw6dOaXo4ekVTqPuHjxItHR0bRp00ZdlpiYyOnTp9m4cSPnz59X/L2QrjErR48excbGhs8++yzV8SvJCxxevnz5o/t7+vQpiYmJKbp7bGxsuHHjRlrDSsHV1ZWgoCBKlSpFVFQUixcvpkuXLuzatStNSZQQn+rt27f4+vry6tUr6pQvyDj/xqCbO+Y6ELmXkaERq8Yvok7/phw5cZSpE79m4tRJSoclskGNGjXYtWuXRtnYsWMpXbo0vXv3VjxRgXQkK2vXrlWPDl63bl2WBfSpvLy81H87OTnh5uZG3bp12bNnD+3bt1cwMpFXjBw5kjNnzmBjYcx3wxqgZ5pf6ZCESJMyRUsxZ+DX9J8znClBX+Pt403tz+soHVaukRCXBCRkUz1pZ25ujoODg0aZqakp+fPnT1GulDQnK9WqVUv174yysrJCT0+P6OhojfLo6GhsbW0/ef/J8uXLR8mSJfnnn38ybZ9CvE9oaCgLFy4EYN2AmhQt7aRwREKkT6cGbfn1j9/Y+utOOnfqzLmLEVhbWysdVo6mb6iHibnBu4naMjj/SXqZmBugb6h8i0hmyXDb9PPnz9m2bRvXr18HoGzZsrRp0ybNa0wYGhpSsWJFwsPD1TPiJiUlER4ejp+fX0bDSuH169fcuXNHBtyKLHf79m31dPojmjnRxMdLxqmIHGnu4Kn8fvkMNx7eJqBrD3bs3inT8X8CIxN9PmtaKketDbR+/fpMjObTZehITp8+Tb9+/bCwsMDZ2Rl4d2CLFy9m2bJlVK1aNU376dGjB6NHj8bZ2RlXV1fWrl1LbGysepDPqFGjKFiwIMOHDwfeDcpNTo7i4uJ49OgRly9fxtTUlBIlSgAwc+ZM6tatS5EiRYiMjGThwoXo6urSrFmzjByqEGkSHx9Pp06dePbsGdXK2jKtVxOZTl/kWBam5oSMC6bhkLbsDPuRpcFLGDA4UOmwcjQjE/1cs06PEjL0zE2ZMoUmTZowadIk9cCbxMREJk+ezJQpU1IM1HmfJk2a8OTJE4KDg4mKiqJ8+fKEhISou4EePHiAru7/JtCKjIykVatW6turVq1i1apVVKtWTZ0FPnz4kGHDhvHs2TOsra2pUqUKW7dulWZMkaXGjx9PeHg4lmZGbB5aD8N8mdeVKYQSKju6MaHnKMavmM7wUcOpVccTt0puSocl8qgMJSu3b99mwYIFGiOE9fT08Pf3Z+fOnenal5+f33u7ff7bDGVvb8+VK1c+uL9vvvkmXfUL8an27dvHzJkzAVjZuyqlnFwUjkiIzBHYtheH/zzGwT8O075NW/6IOIOFhYXSYYk8KEPzfleoUCHVy4tv3LiBk5MMKBR5x/379+natSsAA+qXo20Tb5lOX+QaydPxF7YuyLVb1+ndPQCVSqV0WCIPSnPLyl9//aX+u1u3bkybNo3bt2/j5vauWfDcuXNs3LiRESNGZH6UQmihxMRE/Pz8iIqKwq2kNXP7NwF9Y6XDEiJT2Vhas+qrRTQb0ZEtod/jtehz+g8aoHRYIo9Jc7LSqlUrdHR0NLLq2bNnp9hu+PDhNGnSJHOiE0KLTZs2jV9//RUzYwO2DPXGOH9BpUMSIkvUdK7KhB4jmbhyBkNHDKO6Rw0qV6msdFgiD0lzsvLzzz9nZRxC5Ci//PILkydPBmBpz89wdHZXNiAhstig9n04HnGSfad/pX2bdvwZcUY9UagQWS3NyUrRokWzMg4hcoz79+/TqVMnkpKS6OFVmq4t68s4FZHr6erqsmz0N9Tu14Qb/9ykZ9cebPthu8y/IrLFJ130/ffff3P//n3i4+M1yuvVq/dJQQmhreLj4/H19SUyMhLXEtYsGtQMDGScisgbrPLlZ9VXi2gyvAM7doWy6JtgBg0brHRYOcLbmNfEv32bbfUZGBlhZGqWbfVltQwlK3fu3CEwMJCrV69qjGNJzrDTspChEDnRuHHjOHr0KBYmhmwbUQ9T60JKhyREtqpWoTKTA8YwbvlUho8eSY1aHlStnraJQPOqtzGvCd++mdgXz7OtTpN8ltRs2zHXJCwZSlamTZuGvb09a9asoV69emzbto2nT58yc+ZMRo8endkxCqEVdu7cqR5UvrpfdcpVkAmyRN40oG0AxyNO8tOJA7Rv244z589iZWWldFhaK/7tW2JfPEff0BADo6xviY1/+4bYF8+Jf/s2zcnKwoULWbRokUZZqVKl2Lt3b1aEmG4ZSlbOnDnD2rVrsba2RldXFx0dHT777DOGDRvG1KlT0z0xnBDa7vr16/j7+wMwtIkjbRvXlXEqIs/S0dFh8ag5XOjXlNv3/qF7p278sOdHGb/yEQZGxhiamGRLXQlxcel+TLly5Vi9erX69r8nflVahs62SUlJmJm9y9asrKyIjIwE3g3CvXnzZuZFJ4QWiI2NpV27djx//hwPxwLM7NtU5lMReV5+c0tWj1+Mob4Bu/btZvb0mUqHJD6Rnp4ednZ26n/atExNhpKVcuXKqae9d3NzIyQkhD/++IPFixdTrFixTA1QCKUNHjyYs2fPYpvPhC3D62NgIev+CAHv1g+a1nc8AGMnjOOXgzLFRU52+/ZtPD09qVevHsOHD+f+/ftKh6SWoWSlf//+JCUlAfDFF19w9+5dunTpwuHDhxk3blymBiiEktatW8eKFSvQ0dHhu4Ee2JepoHRIQmiVXi264uvdiqSkJHw7dOSff/5ROiSRAa6urgQFBRESEsKkSZO4d+8eXbp04dWrV0qHBmRwzErt2rXVf5coUYK9e/fy7NkzLC0tpc9S5Brnzp2jX79+AExq60z9unVA3t9CaNDR0eGbIUFcvPEXF279RbsWbfjt5DGMjIyUDk2kg5eXl/pvJycn3NzcqFu3Lnv27KF9+/YKRvbOJ48QfPDgAQ8ePCB//vySqIhcIzo6mtatWxMbG0sjtyJ81aMp6BkoHZYQWsnU2IQNk5eT38yS0+f+YGDfQKVDEp8oX758lCxZUmtayjKUrCQkJDB//nyqVKmCt7c33t7eVKlShW+++SbFBHFC5DSJiYl06tSJmzdvUrpgPr4b1Qxdk3xKhyWEVitZuDgrxi5AR0eHkLUrCfl2hdIhiU/w+vVr7ty5g52dndKhABnsBvr66685cOAAI0eOxN3dHYCzZ8+yaNEinj17pl4zRYicaNy4cRw4cABTIwN2jqyLVeGSSockRI5Qv9rnjPUbwvT13zDwi0G4ubvLhHH/Ev/2jdbWM3PmTOrWrUuRIkWIjIxk4cKF6Orq0qxZsyyIMP0ylKzs3r2befPmpejjKly4MMOGDZNkReRYW7duZebMd5dgrupbDZdKcqIVIj1GdBnEn1fOsffUL7Rt3YY/I85ga5u3r6AzMDLCJJ8lsS+eZ2j+k4wwyWeJQTrGDT18+JBhw4bx7NkzrK2tqVKlClu3btWay5czlKwYGhpib2+fotze3h4DA+nXFznT+fPn6dGjBwAjm5XHt1k9mfhNiHTS1dVl2Zhv8B7QghsPbuPbpgP7fz2gVROMZTcjUzNqtu2o1WsDffPNN1kYzafLULLSpUsXlixZQlBQEIaGhgDExcWxdOlS/Pz8MjVAIbLD06dPad26NTExMfi4FGa6TPwmRIblN7dk/eRvqf9Fa3757VdGDR3J3OB5SoelKCNTs1yzTo8S0pysDBw4UOP28ePHqVOnDk5OTgD89ddfxMfHU7NmzcyNUIgslpiYSJcuXbh+/Tol7CzYPLIJ+mba0fQpRE5VsZQTC4fNIiBoEPMWfoOLmwv+AT2UDkvkUGlOViwsLDRuN2zYUON24cKFMyciIbLZV199xZ49ezA21Cd0RF1sipZWOiQhcoW2dZtz6cZfzN2ymL79++Ho5ETNWvKDVqRfmpOVoKCgrIxDCEWsX7+eGTNmABDSuyqVPqsmE78JkYnG9RjO5VtXCDt5kNatWnH6z99lWRaRbp80evDJkyf8/vvv/P777zx58iSzYhIiWxw/fpxevXoBMLZlBbq0bCADaoXIZLq6unw7dj7lizvw6HEkrZq2ICYmRumwRA6ToTNzTEwMY8eOxdPTEz8/P/z8/KhduzZffvklsbGxmR2jEJnu9u3btG7dmri4OFpVLcbUPs1BX6YHFyIrWJias+nrldhYWPHn+bP09PNHpVIpHZbIQTKUrMyYMYPTp0+zdOlSdcvKkiVLOH36tLpJXQht9erlS1q0aEFkZCRuJa1ZP6I5uiaWSoclRK5WsnAx1k5Ygr6ePltCv2fapKmSsIg0y1Cysm/fPqZNm4aXlxfm5uaYm5vj5eXF119/zb59+zI7RiEyTWJCAl29yhAREUHB/Kb8OKYR5nYp5wwSQmQ+T7eazBrwbtLQ8VMmsK7ffElYRJpkaJ6VN2/epDojoY2NDW/eZM90wkKkl0qlwrVpNy6dicJQD0KH1qJ4uYpKhyVEntKzeRcuXr/EyrCN9Fk9hgo9alG1RjWlw8pySW8SUMUlZVt9Ooa66Bpn6CteK2XoSNzd3QkODmbWrFnqZcDfvHnDokWL1GsFCaFtVq1dx6X9mwBY2cKYmtU+kyt/hFDAlD5jOXTlBNevX6dJ86b88ccfFC9eXOmwskzSmwRe/PwPia+zb6FfPTMD8tUrnmsSlgwdxZdffkmvXr1STApnZGTEypUrMzVAITLD4cOHGdC3DwBjPQ3xczUEJFERQgkG+ga0a9eO1atXExkZScOGDTl58iT58uXO1c1VcUkkvo5HR18XHcOsX3ZAFZdI4uv4dy056ZiI+9GjR8yePZvffvuN2NhYSpQowfTp03Fxccm6YNMoQ8mKo6Mj+/fvZ9euXdy4cQOAZs2a0bx5c4yNZYpyoV0uXbpEq1atiIuLw8KhBlO9LyodkhB5nrGxMZ07d2b1qtX89ddftGzZkv379+fq9eV0DPXQNcr6ZCUJUCWkr8vp+fPndOrUierVq7NixQqsrKy4ffs2lpbacfFBupOV+Ph4GjduzLfffkuHDh2yIiYhMs2DBw9o0qQJz549o2A5VyybDUJXp7/SYQkhAEtLS74cM5YJkydy6NAhevfuzerVq9GR7tlst2LFCgoVKqQxAaw2Td6X7quBDAwMeJuJK0du3LgRb29vXFxcaN++PREREe/d9tq1awwaNAhvb28cHR1Zs2bNJ+9T5F6vXr2iWbNm3L59m/yFi9N65DfoGshcKkJok7JlyvDVV1+ho6PD2rVrmTp1qtIh5Um//PILzs7OfPHFF9SsWZNWrVqxdetWpcNSy9Cly126dGHFihUkJCR8UuVhYWEEBQURGBhIaGgoTk5OBAQEEB0dner2sbGx2NvbM3z4cOzs7DJlnyJ3SkhIwNfXlz///BPTfFa0GL2QUsWKKB2WECIVtWrVon//dy2eEyZMYOPGjQpHlPfcuXOHTZs2UbJkSVauXEmnTp2YOnUqoaGhSocGZHDMyvnz5wkPD+fo0aM4OjpiYmKicf+iRYvStJ/Vq1fToUMH2rZtC8DkyZM5dOgQ27dvp0+fPim2d3V1xdXVFYC5c+dmyj5F7qNSqQgMDCQsLAwDQ2MaDf0Gt/KOJCTJfA5CaKt27dpx//59du7cib+/P3Z2djRo0EDpsPIMlUqFs7Mzw4YNA6BChQpcu3aNzZs307p1a4Wjy2DLSr58+WjYsCG1a9emQIECWFhYaPxLi7i4OC5evIiHh8f/gtHVxcPDgzNnzmQkrCzZp8h5goKCWL58OTo6OtTt/zU1a9aQPnAhcoDAwEA8PT1JSEigdevW/P7770qHlGfY2dlRpkwZjbLSpUtz//59hSLSlK6WlaSkJEJCQrh58ybx8fHUqFGDQYMGZegKoKdPn5KYmIiNjY1GuY2NjfoKI23Yp8hZli9fzrhx4wCo0WU49Ro1Q09XEhUhcgI9PT2++uorRo0aRUREBI0aNSI8PJxy5copHVquV7lyZW7evKlRduvWLYoWLapQRJrS1bKydOlSvvnmG8zMzChYsCDr169n8uTJWRWbEOmybds2+vXrB4B78x606NQTAz1ZRVmInMTQ0JCpU6dSqlQpoqOj8fHx4eHDh0qHlSlUcYkkvc36f6q4xHTH1r17d86dO8eyZcu4ffs2u3btYuvWrXTu3DkLnon0S1fLyg8//MDEiRPp2LEjAMePH6dPnz5MmzYNXd30fSlYWVmhp6eXYuBrdHR0qlP5K7VPkTMcPHiQzp07o1KpcKrbmja9h2NkkPXzGQghMp+5uTmzZ88mMDCQf/75Bx8fH44fP55jJ43TMdRFz8zg3URt6Zz/JKP0zAzQMUz797KrqyuLFi1i3rx5LF68GHt7e7788ktatGiRhVGmXbqSlfv37+Pl5aW+7eHhgY6ODpGRkRQqVChdFRsaGlKxYkXCw8Px8fEB3nUzhYeH4+fnl659ZeU+hfY7deoUrVq1Ij4+ntJV69Fh0CTMjXPvxFJC5AXW1tbMnj2bQYMGcfHiRZo0acLPP/+sXuIlJ9E11idfveJavzZQ3bp1qVu3bhZF9GnSdSSJiYkp3ij6+vrEx2dsvYMePXowevRonJ2dcXV1Ze3atcTGxtKmTRsARo0aRcGCBRk+fDjwbgDt9evX1X8/evSIy5cvY2pqSokSJdK0T5G7XL58mSZNmvD69WvsnavjO3IW+c1lFmUhcgN7e3tmzJjB0KFDOXbsGK1bt+aHH37IkbPc6hrrp2vqe6EpXcmKSqVizJgxGBoaqsvi4uKYNGmSxuXLab10uUmTJjx58oTg4GCioqIoX748ISEh6i6bBw8eaHQvRUZG0qpVK/XtVatWsWrVKqpVq8b69evTtE+Re/zzzz80aNCA6OhoCpapiO+YBdjlN1c6LCFEJnJ0dGTq1KmMHTuWPXv24Ovry/fff4+ennTz5iXpSlZSu9b6U/uz/Pz83ttFk5yAJLO3t+fKlSuftE+RO9y7d4+6dety9+5drIuWov2XiylawErpsIQQWaBy5cpMmjSJCRMmEBoair+/P2vXrk33WEmRc6UrWfn3mgFCKOXhw4d4e3tz48YNLAva027cMkoXK6x0WEKILFSzZk3GjRvH119/zYYNGzA1NWXZsmUyh1IeIWmpyFEiIyOpV68eV69eJZ9tYdp+9S1OZUsqHZYQIht8/vnnjBo1Ch0dHZYvX86wYcNQqWRm6rxAkhWRYyTPuXDp0iXMrQvQ+qtvqehQ5uMPFELkGg0bNmTw4MEAzJ8/n/HjxysckcgOkqyIHOHp06fUr1+f8+fPY5bfllbjvsW1vIM0AQuRB7Vo0UK98OG0adOYOHGiwhGJrCbJitB6z58/p1GjRpw5cwbTfFa0HLeMSs7lJVERIg9r3749AQEBAEyZMoVx48ZJl1AulqFVl4XILk+ePKFhw4b8/vvvmFjkp8XYpVRxdZZERQhBly5d0NHRISQkhOnTp5OQkMCMGTO08vzw5s2bDM9JlhEGBgYZWrdPW0myIrRWVFQU9evX59y5c5jks6LF6MVUreyulSciIYQyOnfujJ6eHt9++y2zZs0iISGBOXPmaNV54s2bNxw+fJiYmJhsq9PU1BQvL680Jyze3t7cu3cvRXnnzp21optNkhWhlR48eKAeTGuW35YWXy7hMzdXrToBCSG0g6+vL3p6eixZsoR58+YRFxdHcHCw1pwv4uPjiYmJQV9fP1tm302uLz4+Ps3JyrZt20hM/N8CiNeuXaNHjx40atQoq8JMF0lWhNa5e/cu3t7eXLt2DXPrArQa962MURFCfFC7du3Q09Nj4cKFLFq0iPj4eJYsWaJVE8cZGBhk29pGCQkJ6dre2tpa4/by5cspXrw41apVy8ywMkx7XkUhgJs3b1KnTh2uXbtGPrvCtJ0QIomKECJNWrduzdChQwH49ttv8fPzS/eXtni3jM6PP/5I27ZttebcK8mK0Brnz5+nVq1a3Lx5E8uCxWg/caVcniyESJfmzZszatQodHV12bRpEy1atODNmzdKh5WjHDx4kJcvX6a6xI5SJFkRWuHYsWPUqVOHBw8eYFOsLJ0mr6SiQxlJVIQQ6daoUSMmTZqEgYEBe/bsoX79+rx48ULpsHKM7du3U6dOHQoWLKh0KGqSrAjF7d69Gx8fH549e0ZhBzf8vl6NQ+kSSoclhMjBPD09mTFjBiYmJhw9epQ6deoQFRWldFha7969exw/fpx27dopHYoGSVaEotatW0erVq148+YNJdw96Tp5OSWKFFA6LCFELlCpUiXmzZtHvnz5OHfuHDVr1uTWrVtKh6XVduzYgY2NDZ9//rnSoWiQZEUoQqVSMXv2bLp3705iYiIOtZrSdfxCCtnkVzo0IUQu4ujoSHBwMLa2tly/fp2qVaty+vRppcPSSklJSezYsYNWrVqhr69dFwtrVzQiT0hISGDQoEEsW7YMANdGXWjTfwz5TAwVjkwIkRsVL16cRYsWMWbMGG7duoWXlxebN2+mRYsW2RpHds1gm9F6jh8/zv3792nbtm0mR/TpJFkR2erFixf4+vqyd+9edHR0qN5xCC38emNsoKd0aEKIXKxAgQIsXLiQCRMmcObMGVq3bs2CBQsYOHBgltdtYGCAqakpMTEx2XYptampabonoPP09OTKlStZFNGnkWRFZJs7d+7QrFkzIiIiMDA0pm7/r6nXqBkGetIbKYTIemZmZsycOZM5c+awf/9+Bg0axM2bN5k9e3aWTh5nbGyMl5eXrA30CSRZEdnizJkzNGvWjPv372OW34bGw+ZTvVpV9HTl0mQhRPbR19dn9OjRFCpUiHXr1jFv3jz+/vtvNm7ciLm5eZbVa2xsnKuSh+wmP2lFlvv+++/x9PTk/v372NiXwffrddSsLomKEEIZOjo6+Pv7M2rUKPT19fnxxx+pXr26XCmkxSRZEVkmKSmJcePG0aFDB2JiYijmUoNu09fh7FhWJnsTQiiuUaNGzJs3D0tLSy5dukSVKlU4fPiw0mGJVEiyIrLE8+fPadGiBdOnTwfeXfHjP2UZxQrZKhyZEEL8j7OzM8uWLaN06dI8efIEHx8f9ZWKQntIsiIy3ZUrV6hevTo//fQT+oZG1O03hU6DxmFlZqJ0aEIIkULBggVZtGgRtWvXJiEhgf79+9OrVy/evn2bof0lJSVlcoTaJ7uPUQbYikwVGhqKv78/L168wMKmIA2HzKV61c9kfIoQQqsZGxszadIk1q9fz9q1a1m5ciV//vknoaGhlCiRtuU/DA0N0dXV5f79+9jZ2WFoaJjrurxVKhVxcXFERUWhq6uLoWH2zI8lyYrIFHFxcYwZM4ZvvvkGgMIO7rQaMZeyJYrmug+rECJ30tHRoVu3bpQrV46goCDOnDmDu7s7GzdupEmTJh99vK6uLqVKleLBgwfcv38/GyJWjqmpKcWLF8/SS77/TZIV8cn++ecffH19OXHiBPBufEqL3iOwtjBVODIhhEi/mjVrsnz5ciZMmMDff/9Ns2bNGDt2LFOmTEFP78MTWBoaGlK8eHESEhJITEzMpoizl56eHvr6+tn6Q1SSFfFJ9uzZg5+fH0+ePMHYzAKvXhP5vGETjPRlRlohRM5VqFAhFi1axMKFC/npp5+YPn06x44dY9OmTRQuXPiDj9XR0cHAwCDdM8iK95MBtiJD3r59y6hRo2jSpAlPnjyhQOkKdJz+HfWbNJNERQiRKxgaGjJ8+HBGjx6NkZERhw8fxtnZmV27dikdWp4jyYpIt8uXL1OjRg1mz54NQAWf9gTMXI9reQd0ZXyKECKXadiwIcuWLaNkyZI8efKEFi1aMGDAAGJjY5UOLc+QZEWkmUqlYsmSJVSuXJmzZ89iks+KhoPn0HXYZOwss26aaiGEUFqJEiVYtmwZLVu2BGDp0qVUqVKFCxcuKBxZ3iDJikiTyMhImjdvTmBgIG/evKGYS026zdpKA+n2EULkEYaGhgwePJhp06ZhaWnJ5cuXqVKlCrNnz861g2m1hVYkKxs3bsTb2xsXFxfat29PRETEB7ffs2cPjRo1wsXFhebNm6eYHnnMmDE4Ojpq/AsICMjKQ8i1VCoVW7ZsoWLFiu8meTMwpGaX4QR8vRzH0sXlsmQhRJ5Ts2ZNQkJCqFy5MnFxcYwaNYpatWpx7do1pUPLtRRPVsLCwggKCiIwMJDQ0FCcnJwICAggOjo61e3//PNPhg8fTrt27di5cyf16tUjMDCQq1evamxXu3Ztjh49qv43b9687DicXOXhw4e0bduWjh078vjxY2yLl6P91+tp07U3+UyzZyIgIYTQRjY2NsyePZvBgwdjYmLCyZMncXV1Zf78+XliBtvspniysnr1ajp06EDbtm0pW7YskydPxtjYmO3bt6e6/bp166hduza9evWiTJkyDBkyhAoVKrBhwwaN7QwNDbGzs1P/s7S0zI7DyRVUKhUbN26kYsWKhIaGoqunT+VWfeg7dwtVK7vLbLRCCMG7S5RbtmzJypUrcXFx4c2bNwwdOpQ6depIK0smUzRZiYuL4+LFi3h4eKjLdHV18fDw4MyZM6k+5uzZs9SsWVOjzNPTk7Nnz2qUnTp1ipo1a9KwYUMmTpzI06dPMz3+3Oj27du0aNFCPXeKXUknOkxdT8e+Q7GxNFM6PCGE0DqFChVi/vz5DBw4ECMjI44dO4azszOTJ0/O8PpCQpOiycrTp09JTEzExsZGo9zGxobHjx+n+pjHjx9ja2v7we1r167NzJkzWbNmDSNHjuT06dP07t1bBkB9QFxcHDNnzqR8+fLs3r0bPX19qrTpR9+5m6hWpTL6eoo3wgkhhNbS0dGhTZs2rFy5End3d+Li4pg0aRKurq4cOXJE6fByvFw5g23Tpk3VfycPsPXx8VG3tghNR44coX///ly6dAmAIk6V8e45FjdXF+nyEUKIdChSpAhz585l//79LFu2jKtXr+Ll5UX37t2ZO3duih/nIm0U/blsZWWFnp5eisG00dHRKVpPktna2qZodfnQ9gDFihXDysqK27dvf3rQuUhUVBQ9evTAy8uLS5cuYZLPis/7TKLfrHVUdneVREUIITJAR0eHhg0bsnbtWho0aADA2rVrKVeuHMuWLZNW/gxQNFkxNDSkYsWKhIeHq8uSkpIIDw+nUqVKqT7G3d1dvWBesuPHj+Pu7v7eeh4+fMizZ8+ws7PLlLhzurdv3zJnzhzKlSvHmjVrAChftzW95v9A87YdMTeW9SyEEOJT5cuXT70afbFixXj69Cn9+/enUqVKHDp0SOnwchTFByL06NGDrVu3EhoayvXr15k0aRKxsbG0adMGgFGjRjF37lz19t26deO3335j1apVXL9+nYULF3LhwgX8/PwAeP36NTNnzuTs2bPcvXuX8PBwBgwYQIkSJahdu7Yix6gtVCoVoaGhVKxYkZEjR/L8+XNsSzjSdtJquo+cTin7gjJvihBCZDI3NzdWrlxJ3759MTMz4/z589StW5c2bdpw8+ZNpcPLERQfs5K8EF5wcDBRUVGUL1+ekJAQdbfOgwcP0NX9X05VuXJl5syZw/z585k3bx4lS5Zk8eLFODg4AO+Wrr569So7d+7k5cuXFChQgFq1ajF48GAMDfPu3CBnzpxh6NCh6gn0zPLb8lm7/nzetB2WZsYKRyeEELmbvr4+vr6+NGzYkBUrVrB3715CQ0MJCwtjyJAhjB07VqbY+ADFkxUAPz8/dcvIf61fvz5FWePGjWncuHGq2xsbG7Ny5cpMjS8nu3HjBpMmTWLDhg2oVCr0DY1wbtgFb9/eFLWzkpYUIYTIRvnz52fkyJG0bt2a4OBgLly4wMyZM1m+fDljx45l4MCBmJiYKB2m1lG8G0hkjXv37tG/f38cHR1Zv349KpWKsjUa4v9NKF0CR2FfwFoSFSGEUEjZsmVZsGABEydOpGjRojx9+pRRo0ZRpkwZVqxYQUJCgtIhahVJVnKZx48fM3LkSMqWLcuyZctISEigmEtNOkzdQK8J86lQroxc5SOEEFpAR0cHLy8v1qxZw9ChQ7G1teXBgwf06dOH8uXLs3nzZrly6P9JspJLREZGMnbsWEqXLs2cOXN48+YNhR3dafXVcvrPWEmNalUx1JeXWwghtI2enh7Nmzdn/fr19O7dGwsLC/7++286depEhQoVWL9+fZ5vaZFvrxzuzp07DB48mJIlSzJjxgxevnyJXUlHmowIZsCcDdSp44WxgZ7SYQohhPgIIyMjOnXqxMaNG+ncuTNmZmZcvXqVbt264eDgwMqVK4mLi1M6TEVIspJD/f333+rFHIODg4mNjaVgmYo0GjqPgQu24dOgIWZGMl+KEELkNObm5vTq1YtNmzbRtWtXLCwsuHnzpvqcv3DhQl69eqV0mNlKkpUcRKVSceTIEVq3bq3OsuPj4ylavgrNxywm8JstNGjcFAuTvHuJthBC5Bbm5ub06NGDTZs20bNnTywtLbl79y5ffPEFxYoVY8yYMdy/f1/pMLOFJCs5QFxcHOvXr6dKlSp4eXmxc+dOVCoVxd1q0XbiKgLnrKeut4/MPCuEELmQqakpfn5+bNq0if79+1OoUCGePXvGzJkzKVmyJN26dePcuXNKh5mltGKeFZG6yMhIli9fzuLFi3n48CEA+oZGlK3VhKpNu1CxQkUZNCuEEHmEsbEx7du3p02bNhw+fJht27bx119/sX79etavX0+tWrUIDAykTZs2GBkZKR1uppJkRcskJSXxyy+/sHz5cnbu3El8fDwA5lZ2lK/XnhpNfSleuKBcfiyEEHmUnp4e3t7eeHt7c/78ebZs2cKJEyc4duwYx44dw9bWloCAAPr27UupUqWUDjdTSLKiJR4+fMiaNWtYsWIFN27cUJcXLOOMc4OO1PBugnU+U5nITQghhJqLiwsuLi48evSInTt3sn//fh4/fszMmTOZNWsWDRs2pF+/fjRp0gQDg5w7VECSFQW9ffuWsLAw1q9fz65du9TX0RuamlPWozGV6relorOrXHoshBDigwoWLEjfvn3p2bMnR44cYdeuXURERLB371727t2Lra0tnTt3xt/fH3d39xz3w1eSlWymUqk4fvw469evZ+vWrTx9+lR9X6Fyrjh93pqqdRtT0CY/ujnszSSEEEJZBgYG1KtXj3r16nH79m127tzJoUOHePz4McHBwQQHB+Ps7Iy/vz9dunShUKFCSoecJpKsZAOVSsWlS5fYsmULGzZs0FgS3MzKjjI1GuLm3YIKFZwxklYUIYQQmaBEiRIMHjyYwMBAjh07xr59+/j999+5cOECI0aMYNSoUXz++ef4+vrSunVr7OzslA75vSRZySIqlYpz586xbds2tm3bxpUrV9T3GRibUOozb8rXbopb1VpYmhnluCY5IYQQOYO+vj5eXl54eXnx/Plz9u/fz8GDB7l27Rq//PILv/zyCwMGDKBu3brqxMXGxkbpsDVIspKJkpKS+OOPP9i2bRvbt2/n+vXr6vv09A0o6lydch6NqFK7PgWsLNGVK3qEEEJkI0tLS9q3b0/79u25c+cOBw8e5OjRo9y8eZODBw9y8OBB+vXrh7e3Ny1btqR58+YUL15c6bAlWflUL1684MCBA4SFhREWFqaeDwXezYlSzNWD0lXr4V7Lm4K2VujryrwoQgghlFesWDF69OhBjx49uH37Nj///DNHjx7l1q1bHDhwgAMHDjBw4EBcXV1p0aIFzZs357PPPkNXge8xSVbSSaVScfXqVX766Sd++uknfvvtN/VcKAAGxqYUd6tFmWr1cKvxOQVs8sucKEIIIbRaiRIl6NmzJz179uTWrVscOnSIkydPcvXqVSIiIoiIiGDq1KkULFiQJk2a0LBhQ+rVq4etrW22xCfJShrcv3+fn3/+mZ9//plffvmFO3fuaNyfv1Bx7N1qUaZyHSpWroZ1PjO5kkcIIUSOVLJkSfz9/fH39+fJkyccPXqUEydOcO7cOR49esTq1atZvXo1Ojo6uLu7U79+ferXr4+npyfGxsZZEpMkKx8wYsQIDh8+zF9//aVRrqdvQCHHShR3q0WF6p9TqkxZTAz0ZJCsEEKIXMXa2poWLVrQokUL4uLi+P3339WJy507dzhz5gxnzpxh1qxZGBsbU6tWLWrXrp3pcUiy8gErVqwgKSkJdHQoUKo8Rcp/RknXGji5f4aNZT7p3hFCCJFnGBoa4uHhgYeHB/Bu/bqTJ0/y559/EhERwdOnT/n555/59ddfKVu2bKbWLcnKB5St3ZIylTxwrFSTQnY2smigEEII8f8KFChA8+bNad68OUlJSVy/fp0TJ04QHh7+7od+JpJk5QNa9xtNQRsrpcMQQgghtJquri7lypWjdOnSFC5cmG3btmXu/jN1b0IIIYQQmUySFSGEEEJoNUlWhBBCCKHVJFkRQgghhFaTZEUIIYQQWk2SFSGEEEJoNUlWhBBCCKHVJFkRQgghhFaTZEUIIYQQWk0rkpWNGzfi7e2Ni4sL7du3JyIi4oPb79mzh0aNGuHi4kLz5s05fPiwxv0qlYoFCxbg6emJq6sr/v7+3Lp1KwuPQAghhBBZRfFkJSwsjKCgIAIDAwkNDcXJyYmAgACio6NT3f7PP/9k+PDhtGvXjp07d1KvXj0CAwO5evWqepsVK1awfv16Jk2axNatWzExMSEgIIC3b99m12EJIYQQIpMonqysXr2aDh060LZtW8qWLcvkyZMxNjZm+/btqW6/bt06ateuTa9evShTpgxDhgyhQoUKbNiwAXjXqrJu3Tr69++Pj48PTk5OzJo1i8jISA4ePJidhyaEEEKITKDoQoZxcXFcvHiRvn37qst0dXXx8PDgzJkzqT7m7Nmz+Pv7a5R5enqqE5G7d+8SFRWlXsIawMLCAjc3N86cOUPTpk0/GpdKpXq3r6inxMZl7sqRQjkJiUmo4t/wSk/nXUHkLTAwUzSmjIhJeIvq7bv36MOnD1ElGSsTSOwbYv7/s/Lm3j2SYhOyvEpVQgIxKhVvE2IBePzwKbrZsBp6UmIScQmxxCUmvqv3wQNiXr3O8npTxJGUSFxiIq/j3x1/4qNn6CS/n3OQuIR44uPjAXj8OJq3ifEKRyQyS2Jiovq1Tf4uzQyKJitPnz4lMTERGxsbjXIbGxtu3LiR6mMeP36Mra1tiu0fP34MQFRUlLrsfdt8zOvX705CpxcNTtP2ImepQsH//+t3RePIDOGcBc4qVv/O5D+Onczein8b9v//Z2+1audTPz9ll5URg979sVvRMIT4oNevX2NhYZEp+1I0WdFWBQoU4PDhw5iZmaGjk/N+tQghhBBKUalUvH79mgIFCmTaPhVNVqysrNDT00sxmDY6OjpF60kyW1vbFC0k/97ezs5OXfbvJyo6OhonJ6c0xaWrq0uhQoXSfBxCCCGE+J/MalFJpugAW0NDQypWrEh4eLi6LCkpifDwcCpVqpTqY9zd3Tlx4oRG2fHjx3F3dwfA3t4eOzs7jX2+evWKc+fOvXefQgghhNBeil8N1KNHD7Zu3UpoaCjXr19n0qRJxMbG0qZNGwBGjRrF3Llz1dt369aN3377jVWrVnH9+nUWLlzIhQsX8PPzA0BHR4du3bqxdOlSfv75Z65cucKoUaMoUKAAPj4+ihyjEEIIITJO8TErTZo04cmTJwQHBxMVFUX58uUJCQlRd+s8ePAAXd3/5VSVK1dmzpw5zJ8/n3nz5lGyZEkWL16Mg4ODepvevXsTGxvLhAkTePHiBVWqVCEkJAQjI6NsPz4hhBBCfBodVWZeWySEEEIIkckU7wYSQgghhPgQSVaEEEIIodUkWRFCCCGEVpNkRQghhBBaTZIVYMKECTg6OrJmzZqPbrtx40a8vb1xcXGhffv2REREZH2AIt32799Pz549qV69Oo6Ojly+fPmjj4mPj2fRokX4+Pjg4uJCixYtOHLkSDZE+34ZOY5r164xaNAgvL290/y+/hCVSsWCBQvw9PTE1dUVf39/bt269cHHLFy4EEdHR41/jRo1Sle96f2s7dmzh0aNGuHi4kLz5s05fPhwuurLSL07duxIcZwuLi4ZqjfZ6dOn6devH56enjg6On50AdbIyEiGDx9Ow4YNcXJyYtq0aZ9Uf2ZJ73HAu+e+cePGuLq60rBhQ3bu3Jn1gYpPsnz5chwdHT/6vvvUz2eeT1YOHDjAuXPn0jQtcFhYGEFBQQQGBhIaGoqTkxMBAQEpZuAVyouJiaFy5cqMGDEizY+ZP38+W7ZsYfz48YSFhdGxY0cGDhzIpUuXsjDSD8vIccTGxmJvb8/w4cPVMzp/ihUrVrB+/XomTZrE1q1bMTExISAggLdv337wceXKlePo0aPqf999912a60zvZ+3PP/9k+PDhtGvXjp07d1KvXj0CAwO5evVquo41I59xc3NzjeP89ddf01Xnf8XExODo6MjEiRPTtH1cXBxWVlb0798/zbN0Z4f0Hsd3333H3LlzGTRoED/99BNffPEFkydP5pdffsniSEVGRUREsHnzZhwdHT+4XaZ8PlV52MOHD1W1a9dWXb16VVW3bl3V6tWrP7h9u3btVJMnT1bfTkxMVHl6eqq+/fbbLI5UZNSdO3dUDg4OqkuXLn1021q1aqk2bNigUTZw4EDV8OHDsyq8NEvPcfxbWt7XH5KUlKSqVauWKiQkRF324sULlbOzs2r37t3vfVxwcLCqRYsWGa43vZ+1wYMHq/r06aNR1r59e9X48eOztN7t27erqlSpkq460sPBwUF14MCBNG/v5+enmjp1apbFk1FpOQ5fX1/VjBkzNMqCgoJUHTt2zMrQRAa9evVK1aBBA9WxY8c++r7LjM9nnm1ZSUpKYuTIkQQEBFCuXLmPbh8XF8fFixfx8PBQl+nq6uLh4cGZM2eyMlSRTeLj4zE0NNQoMzIy4s8//1QoIuXdvXuXqKgojfe9hYUFbm5uH33f3759G09PT+rVq8fw4cO5f/9+murMyGft7Nmz1KxZU6PM09OTs2fPpqnOjNYL71oQ6tati5eXF/379+fatWtprlP8T1xcXIqJO42MjDh//jzx8fEKRSXeZ8qUKXh5eWl8Xt4nMz6feTZZWbFiBfr6+nTr1i1N2z99+pTExERsbGw0ym1sbFIsrChyJk9PT9asWcOtW7dISkri2LFjHDhwgMjISKVDU0xUVBRAut/3rq6uBAUFERISwqRJk7h37x5dunTh1atXH60zI5+1x48fp1j8NL2fzYzUW6pUKaZPn86SJUuYPXs2KpWKjh078vDhwzTXK97x9PRk27ZtXLhwAZVKxfnz59m2bRvx8fE8ffpU6fDEv/z0009cunSJ4cOHp2n7zPh85olk5ccff6RSpUrqf6dOnWLdunUEBQWho6OjdHjiE/339f39998ztJ9x48ZRokQJGjdujLOzM1OmTKFNmzYayz1kpcw6jsyMISEhIUP78fLyonHjxjg5OVG7dm2WL1/Oixcv2LNnTyZHrKxKlSrRqlUrypcvT7Vq1Vi4cCHW1tZs3rxZ6dBynAEDBlC7dm18fX2pWLEiAwYMoFWrVgDZ9hkUH/fgwQOmTZvG7Nmzs3UJG8XXBsoO3t7euLm5qW/v3buX6Oho6tatqy5LTExk5syZrFu3LtUBXVZWVujp6aUYaBcdHZ0iYxTZ67+vb8GCBTO0H2tra5YsWcLbt2959uwZBQoUYM6cORQrViyzQv2gzDqOzIwhLi4OePc+//cg9Ojo6HQN5syXLx8lS5bkn3/++ei2Gfms2drapviVlt7PZmZ8xg0MDChfvnyajlNoMjY2JigoiClTphAdHY2dnR1btmzBzMwMa2trpcMT/+/ixYtER0erFxuGd9+fp0+fZuPGjZw/fx49PT2Nx2TG5zNPJCvm5uaYm5urb3fo0EEjUQEICAigZcuWGi/AvxkaGlKxYkXCw8PVqzcnJSURHh6uXvFZKOO/r++nMjIyomDBgsTHx7N//34aN26cafv+kMw+jsyIQaVSYWdnR3h4OOXLlwfg1atXnDt3jk6dOqV5v69fv+bOnTtpujopI581d3d3Tpw4gb+/v7rs+PHjuLu7pznGzPiMJyYmcvXqVby8vNJcr9BkYGBAoUKFgHdXZ9WtW1daVrRIjRo12LVrl0bZ2LFjKV26NL17906RqEDmfD7zRLLyX1ZWVlhZWWmUGRgYYGtrS+nSpdVl3bt3p379+uoTVY8ePRg9ejTOzs64urqydu1aYmNj35vgCOU8e/aMBw8eqMeb3Lx5E3iX4Sd/YY4aNYqCBQuq+13PnTvHo0ePKF++PI8ePWLhwoUkJSXRq1cvZQ6CjB1HXFwc169fV//96NEjLl++jKmpKSVKlEhX/To6OnTr1o2lS5dSokQJ7O3tWbBgAQUKFFB/oUPKz8rMmTOpW7cuRYoUITIykoULF6Krq0uzZs3SVO/HPmv/PeZu3brRtWtXVq1ahZeXF2FhYVy4cIEpU6ak63jTW++iRYtwd3enRIkSvHjxgpUrV3L//n3at2+frnr/7fXr1xotM3fv3uXy5ctYWlpSpEgR5s6dy6NHj5g1a5Z6m+T5d16/fs2TJ0+4fPkyBgYGlC1bNsNxfKr0HsfNmzeJiIjAzc2NFy9esHr1aq5du8aMGTOUOgSRCnNzcxwcHDTKTE1NyZ8/v7o8Kz6feTJZSas7d+5oDOxq0qQJT548ITg4mKioKMqXL09ISIh0A2mhX375hbFjx6pvDx06FICBAwcyaNAg4F3f679/sb19+5b58+dz584dTE1N8fLyYtasWeTLly97g/+XjBxHZGSkuq8fYNWqVaxatYpq1aqxfv36dMfQu3dvYmNjmTBhAi9evKBKlSqEhIRo9Ff/97Py8OFDhg0bxrNnz7C2tqZKlSps3bo1zc35H/us/feYK1euzJw5c5g/fz7z5s2jZMmSLF68OMVJNbPrffHiBePHjycqKgpLS0sqVqzI5s2bPylJuHDhgsbA/6CgIABat27NjBkziIqK4sGDBxqP+ffrffHiRXbv3k3RokUVnaMkvceRlJTE6tWruXnzJvr6+lSvXp1NmzZhb2+f7bGLT5MVn08dlUqlyopghRBCCCEyg3QECiGEEEKrSbIihBBCCK0myYoQQgghtJokK0IIIYTQapKsCCGEEEKrSbIihBBCCK0myYoQQgghtJokK0IIIYTQapKsCCGEEEKrSbIihBBCCK0myYoQQgghtJosZCiEyBHu3r1LvXr1UpRndIFGIUTOIcmKECJHKFy4MEePHlXffvz4Mf7+/nz22WcKRiWEyA6y6rIQIsd5+/YtXbt2xdramiVLlmgsRy+EyH2kZUUIkeN8+eWXvH79mlWrVkmiIkQeIMmKECJHWbJkCUePHuX777/H3Nxc6XCEENlAkhUhRI6xb98+lixZwooVKyhevLjS4QghsomMWRFC5AhXr16lQ4cO+Pv706VLF3W5gYEB+fPnVy4wIUSWk2RFCJEj7Nixg7Fjx6Yol0uXhcj9JFkRQgghhFaTYfRCCCGE0GqSrAghhBBCq0myIoQQQgitJsmKEEIIIbSaJCtCCCGE0GqSrAghhBBCq0myIoQQQgitJsmKEEIIIbSaJCtCCCGE0GqSrAghhBBCq0myIoQQQgit9n/pYT1TfXwvjQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VariationalDequantization(Dequantization):\n",
        "    def __init__(self, var_flows, alpha=1e-5):\n",
        "        \"\"\"Variational Dequantization.\n",
        "\n",
        "        Args:\n",
        "            var_flows: A list of flow transformations to use for modeling q(u|x)\n",
        "            alpha: Small constant, see Dequantization for details\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__(alpha=alpha)\n",
        "        self.flows = nn.ModuleList(var_flows)\n",
        "\n",
        "    def dequant(self, z, ldj):\n",
        "        z = z.to(torch.float32)\n",
        "        img = (z / 154.0) * 2 - 1  # We condition the flows on x, i.e. the original image\n",
        "\n",
        "        # Prior of u is a uniform distribution as before\n",
        "        # As most flow transformations are defined on [-infinity,+infinity], we apply an inverse sigmoid first.\n",
        "        deq_noise = torch.rand_like(z).detach()\n",
        "        deq_noise, ldj = self.sigmoid(deq_noise, ldj, reverse=True)\n",
        "        for flow in self.flows:\n",
        "            deq_noise, ldj = flow(deq_noise, ldj, reverse=False, orig_img=img)\n",
        "        deq_noise, ldj = self.sigmoid(deq_noise, ldj, reverse=False)\n",
        "\n",
        "        # After the flows, apply u as in standard dequantization\n",
        "        z = (z + deq_noise) / 155.0\n",
        "        ldj -= np.log(155.0) * np.prod(z.shape[1:])\n",
        "        return z, ldj"
      ],
      "metadata": {
        "id": "fQaPwSADJ-n4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CouplingLayer(nn.Module):\n",
        "    def __init__(self, network, mask, c_in):\n",
        "        \"\"\"Coupling layer inside a normalizing flow.\n",
        "\n",
        "        Args:\n",
        "            network: A PyTorch nn.Module constituting the deep neural network for mu and sigma.\n",
        "                      Output shape should be twice the channel size as the input.\n",
        "            mask: Binary mask (0 or 1) where 0 denotes that the element should be transformed,\n",
        "                   while 1 means the latent will be used as input to the NN.\n",
        "            c_in: Number of input channels\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.network = network\n",
        "        self.scaling_factor = nn.Parameter(torch.zeros(c_in))\n",
        "        # Register mask as buffer as it is a tensor which is not a parameter,\n",
        "        # but should be part of the modules state.\n",
        "        self.register_buffer(\"mask\", mask)\n",
        "\n",
        "    def forward(self, z, ldj, reverse=False, orig_img=None):\n",
        "        \"\"\"Forward.\n",
        "\n",
        "        Args:\n",
        "            z: Latent input to the flow\n",
        "            ldj:\n",
        "                The current ldj of the previous flows. The ldj of this layer will be added to this tensor.\n",
        "            reverse: If True, we apply the inverse of the layer.\n",
        "            orig_img:\n",
        "                Only needed in VarDeq. Allows external input to condition the flow on (e.g. original image)\n",
        "\n",
        "        \"\"\"\n",
        "        # Apply network to masked input\n",
        "        z_in = z * self.mask\n",
        "        if orig_img is None:\n",
        "            nn_out = self.network(z_in)\n",
        "        else:\n",
        "            nn_out = self.network(torch.cat([z_in, orig_img], dim=1))\n",
        "        s, t = nn_out.chunk(2, dim=1)\n",
        "\n",
        "        # Stabilize scaling output\n",
        "        s_fac = self.scaling_factor.exp().view(1, -1, 1, 1)\n",
        "        s = torch.tanh(s / s_fac) * s_fac\n",
        "\n",
        "        # Mask outputs (only transform the second part)\n",
        "        s = s * (1 - self.mask)\n",
        "        t = t * (1 - self.mask)\n",
        "\n",
        "        # Affine transformation\n",
        "        if not reverse:\n",
        "            # Whether we first shift and then scale, or the other way round,\n",
        "            # is a design choice, and usually does not have a big impact\n",
        "            z = (z + t) * torch.exp(s)\n",
        "            ldj += s.sum(dim=[1, 2, 3])\n",
        "        else:\n",
        "            z = (z * torch.exp(-s)) - t\n",
        "            ldj -= s.sum(dim=[1, 2, 3])\n",
        "\n",
        "        return z, ldj"
      ],
      "metadata": {
        "id": "QEWs9GEPOV1Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_checkerboard_mask(h, w, invert=False):\n",
        "    x, y = torch.arange(h, dtype=torch.int32), torch.arange(w, dtype=torch.int32)\n",
        "    xx, yy = torch.meshgrid(x, y)\n",
        "    mask = torch.fmod(xx + yy, 2)\n",
        "    mask = mask.to(torch.float32).view(1, 1, h, w)\n",
        "    if invert:\n",
        "        mask = 1 - mask\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_channel_mask(c_in, invert=False):\n",
        "    mask = torch.cat([torch.ones(c_in // 2, dtype=torch.float32), torch.zeros(c_in - c_in // 2, dtype=torch.float32)])\n",
        "    mask = mask.view(1, c_in, 1, 1)\n",
        "    if invert:\n",
        "        mask = 1 - mask\n",
        "    return mask"
      ],
      "metadata": {
        "id": "AZvn75OCOhp0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConcatELU(nn.Module):\n",
        "    \"\"\"Activation function that applies ELU in both direction (inverted and plain).\n",
        "\n",
        "    Allows non-linearity while providing strong gradients for any input (important for final convolution)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat([F.elu(x), F.elu(-x)], dim=1)\n",
        "\n",
        "\n",
        "class LayerNormChannels(nn.Module):\n",
        "    def __init__(self, c_in, eps=1e-5):\n",
        "        \"\"\"This module applies layer norm across channels in an image.\n",
        "\n",
        "        Args:\n",
        "            c_in: Number of channels of the input\n",
        "            eps: Small constant to stabilize std\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(1, c_in, 1, 1))\n",
        "        self.beta = nn.Parameter(torch.zeros(1, c_in, 1, 1))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=1, keepdim=True)\n",
        "        var = x.var(dim=1, unbiased=False, keepdim=True)\n",
        "        y = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        y = y * self.gamma + self.beta\n",
        "        return y\n",
        "\n",
        "\n",
        "class GatedConv(nn.Module):\n",
        "    def __init__(self, c_in, c_hidden):\n",
        "        \"\"\"This module applies a two-layer convolutional ResNet block with input gate.\n",
        "\n",
        "        Args:\n",
        "            c_in: Number of channels of the input\n",
        "            c_hidden: Number of hidden dimensions we want to model (usually similar to c_in)\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            ConcatELU(),\n",
        "            nn.Conv2d(2 * c_in, c_hidden, kernel_size=3, padding=1),\n",
        "            ConcatELU(),\n",
        "            nn.Conv2d(2 * c_hidden, 2 * c_in, kernel_size=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        val, gate = out.chunk(2, dim=1)\n",
        "        return x + val * torch.sigmoid(gate)\n",
        "\n",
        "\n",
        "class GatedConvNet(nn.Module):\n",
        "    def __init__(self, c_in, c_hidden=32, c_out=-1, num_layers=3):\n",
        "        \"\"\"Module that summarizes the previous blocks to a full convolutional neural network.\n",
        "\n",
        "        Args:\n",
        "            c_in: Number of input channels\n",
        "            c_hidden: Number of hidden dimensions to use within the network\n",
        "            c_out: Number of output channels. If -1, 2 times the input channels are used (affine coupling)\n",
        "            num_layers: Number of gated ResNet blocks to apply\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        c_out = c_out if c_out > 0 else 2 * c_in\n",
        "        layers = []\n",
        "        layers += [nn.Conv2d(c_in, c_hidden, kernel_size=3, padding=1)]\n",
        "        for layer_index in range(num_layers):\n",
        "            layers += [GatedConv(c_hidden, c_hidden), LayerNormChannels(c_hidden)]\n",
        "        layers += [ConcatELU(), nn.Conv2d(2 * c_hidden, c_out, kernel_size=3, padding=1)]\n",
        "        self.nn = nn.Sequential(*layers)\n",
        "\n",
        "        self.nn[-1].weight.data.zero_()\n",
        "        self.nn[-1].bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.nn(x)"
      ],
      "metadata": {
        "id": "TLuvD4EpO1QE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_simple_flow(use_vardeq=True):\n",
        "    flow_layers = []\n",
        "    if use_vardeq:\n",
        "        vardeq_layers = [\n",
        "            CouplingLayer(\n",
        "                network=GatedConvNet(c_in=2, c_out=2, c_hidden=16),\n",
        "                mask=create_checkerboard_mask(h=1000, w=16, invert=(i % 2 == 1)),\n",
        "                c_in=1,\n",
        "            )\n",
        "            for i in range(4)\n",
        "        ]\n",
        "        flow_layers += [VariationalDequantization(var_flows=vardeq_layers)]\n",
        "    else:\n",
        "        flow_layers += [Dequantization()]\n",
        "\n",
        "    for i in range(8):\n",
        "        flow_layers += [\n",
        "            CouplingLayer(\n",
        "                network=GatedConvNet(c_in=1, c_hidden=32),\n",
        "                mask=create_checkerboard_mask(h=1000, w=16, invert=(i % 2 == 1)),\n",
        "                c_in=1,\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    flow_model = ImageFlow(flow_layers).to(device)\n",
        "    return flow_model"
      ],
      "metadata": {
        "id": "CSN3J3-DPJ8W"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_flow(flow, model_name=\"MNISTFlow\"):\n",
        "    # Create a PyTorch Lightning trainer\n",
        "    trainer = pl.Trainer(\n",
        "        accelerator=\"auto\",\n",
        "        devices=1,\n",
        "        max_epochs=200,\n",
        "        gradient_clip_val=1.0,\n",
        "        callbacks=[\n",
        "            ModelCheckpoint(save_weights_only=True, mode=\"min\", monitor=\"val_bpd\"),\n",
        "            LearningRateMonitor(\"epoch\"),\n",
        "        ],\n",
        "    )\n",
        "    trainer.logger._log_graph = True\n",
        "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
        "\n",
        "    train_data_loader = train_loader\n",
        "    result = None\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join( model_name + \".ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(\"Found pretrained model, loading...\")\n",
        "        ckpt = torch.load(pretrained_filename, map_location=device)\n",
        "        flow.load_state_dict(ckpt[\"state_dict\"])\n",
        "        result = ckpt.get(\"result\", None)\n",
        "    else:\n",
        "        print(\"Start training\", model_name)\n",
        "        trainer.fit(flow, train_data_loader, val_loader)\n",
        "\n",
        "    # Test best model on validation and test set if no result has been found\n",
        "    # Testing can be expensive due to the importance sampling.\n",
        "    if result is None:\n",
        "        val_result = trainer.test(flow, dataloaders=val_loader, verbose=False)\n",
        "        start_time = time.time()\n",
        "        # test_result = trainer.test(flow, dataloaders=test_loader, verbose=False)\n",
        "        # duration = time.time() - start_time\n",
        "        # result = {\"test\": test_result, \"val\": val_result, \"time\": duration / len(test_loader) / flow.import_samples}\n",
        "\n",
        "    return flow, result"
      ],
      "metadata": {
        "id": "hu5nJx_GPrtZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SqueezeFlow(nn.Module):\n",
        "    def forward(self, z, ldj, reverse=False):\n",
        "        B, C, H, W = z.shape\n",
        "        if not reverse:\n",
        "            # Forward direction: H x W x C => H/2 x W/2 x 4C\n",
        "            z = z.reshape(B, C, H // 2, 2, W // 2, 2)\n",
        "            z = z.permute(0, 1, 3, 5, 2, 4)\n",
        "            z = z.reshape(B, 4 * C, H // 2, W // 2)\n",
        "        else:\n",
        "            # Reverse direction: H/2 x W/2 x 4C => H x W x C\n",
        "            z = z.reshape(B, C // 4, 2, 2, H, W)\n",
        "            z = z.permute(0, 1, 4, 2, 5, 3)\n",
        "            z = z.reshape(B, C // 4, H * 2, W * 2)\n",
        "        return z, ldj"
      ],
      "metadata": {
        "id": "e4s_5lJhRRd2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sq_flow = SqueezeFlow()\n",
        "rand_img = torch.arange(1, 17).view(1, 1, 4, 4)\n",
        "print(\"Image (before)\\n\", rand_img)\n",
        "forward_img, _ = sq_flow(rand_img, ldj=None, reverse=False)\n",
        "print(\"\\nImage (forward)\\n\", forward_img.permute(0, 2, 3, 1))  # Permute for readability\n",
        "reconst_img, _ = sq_flow(forward_img, ldj=None, reverse=True)\n",
        "print(\"\\nImage (reverse)\\n\", reconst_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqM9A68PRX4E",
        "outputId": "60d70bb9-2914-4026-d321-6b0dba8a0218"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image (before)\n",
            " tensor([[[[ 1,  2,  3,  4],\n",
            "          [ 5,  6,  7,  8],\n",
            "          [ 9, 10, 11, 12],\n",
            "          [13, 14, 15, 16]]]])\n",
            "\n",
            "Image (forward)\n",
            " tensor([[[[ 1,  2,  5,  6],\n",
            "          [ 3,  4,  7,  8]],\n",
            "\n",
            "         [[ 9, 10, 13, 14],\n",
            "          [11, 12, 15, 16]]]])\n",
            "\n",
            "Image (reverse)\n",
            " tensor([[[[ 1,  2,  3,  4],\n",
            "          [ 5,  6,  7,  8],\n",
            "          [ 9, 10, 11, 12],\n",
            "          [13, 14, 15, 16]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SplitFlow(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.prior = torch.distributions.normal.Normal(loc=0.0, scale=1.0)\n",
        "\n",
        "    def forward(self, z, ldj, reverse=False):\n",
        "        if not reverse:\n",
        "            z, z_split = z.chunk(2, dim=1)\n",
        "            ldj += self.prior.log_prob(z_split).sum(dim=[1, 2, 3])\n",
        "        else:\n",
        "            z_split = self.prior.sample(sample_shape=z.shape).to(device)\n",
        "            z = torch.cat([z, z_split], dim=1)\n",
        "            ldj -= self.prior.log_prob(z_split).sum(dim=[1, 2, 3])\n",
        "        return z, ldj"
      ],
      "metadata": {
        "id": "BOz6V-xJRZJy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_multiscale_flow():\n",
        "    flow_layers = []\n",
        "\n",
        "    vardeq_layers = [\n",
        "        CouplingLayer(\n",
        "            network=GatedConvNet(c_in=2, c_out=2, c_hidden=16),\n",
        "            mask=create_checkerboard_mask(h=1000, w=16, invert=(i % 2 == 1)),\n",
        "            c_in=1,\n",
        "        )\n",
        "        for i in range(4)\n",
        "    ]\n",
        "    flow_layers += [VariationalDequantization(vardeq_layers)]\n",
        "\n",
        "    flow_layers += [\n",
        "        CouplingLayer(\n",
        "            network=GatedConvNet(c_in=1, c_hidden=32),\n",
        "            mask=create_checkerboard_mask(h=1000, w=16, invert=(i % 2 == 1)),\n",
        "            c_in=1,\n",
        "        )\n",
        "        for i in range(2)\n",
        "    ]\n",
        "    flow_layers += [SqueezeFlow()]\n",
        "    for i in range(2):\n",
        "        flow_layers += [\n",
        "            CouplingLayer(\n",
        "                network=GatedConvNet(c_in=4, c_hidden=48), mask=create_channel_mask(c_in=4, invert=(i % 2 == 1)), c_in=4\n",
        "            )\n",
        "        ]\n",
        "    flow_layers += [SplitFlow(), SqueezeFlow()]\n",
        "    for i in range(4):\n",
        "        flow_layers += [\n",
        "            CouplingLayer(\n",
        "                network=GatedConvNet(c_in=8, c_hidden=64), mask=create_channel_mask(c_in=8, invert=(i % 2 == 1)), c_in=8\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    flow_model = ImageFlow(flow_layers).to(device)\n",
        "    return flow_model"
      ],
      "metadata": {
        "id": "PO2K-xFCRgaJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_num_params(model):\n",
        "    num_params = sum(np.prod(p.shape) for p in model.parameters())\n",
        "    print(f\"Number of parameters: {num_params:,}\")\n",
        "\n",
        "\n",
        "print_num_params(create_simple_flow(use_vardeq=False))\n",
        "print_num_params(create_simple_flow(use_vardeq=True))\n",
        "print_num_params(create_multiscale_flow())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKmVL1dXSISK",
        "outputId": "6305b9a3-edce-4882-c776-240fd4b9dad2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 556,312\n",
            "Number of parameters: 628,388\n",
            "Number of parameters: 1,711,818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flow_dict = {\"simple\": {}, \"vardeq\": {}, \"multiscale\": {}}\n",
        "flow_dict[\"simple\"][\"model\"], flow_dict[\"simple\"][\"result\"] = train_flow(\n",
        "    create_simple_flow(use_vardeq=False), model_name=\"MNISTFlow_simple\"\n",
        ")\n",
        "flow_dict[\"vardeq\"][\"model\"], flow_dict[\"vardeq\"][\"result\"] = train_flow(\n",
        "    create_simple_flow(use_vardeq=True), model_name=\"MNISTFlow_vardeq\"\n",
        ")\n",
        "flow_dict[\"multiscale\"][\"model\"], flow_dict[\"multiscale\"][\"result\"] = train_flow(\n",
        "    create_multiscale_flow(), model_name=\"MNISTFlow_multiscale\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929,
          "referenced_widgets": [
            "21a928b363a848fcbd0eaaa12c583be1",
            "09a5c41ae7a4444fbff61098d039678a",
            "b772bcfd47ab4ea6bdc9e3cf63b57f71",
            "b66c4a8f31e742e38882b689e9115d83",
            "5a2e1eab12f84e79af31a56fb5c94564",
            "882b193bec9d4fdba13253e2a69d5e74",
            "fcca76206c7747fa894e3ffea6f51095",
            "b45bb9ff388e4f8e9ceb7e8bfc704652",
            "8fbdca2822c748ac8c2f06bd1b0500a2",
            "fa7f5c2370eb465587608963a186b13c",
            "1909d3a0a30742a0b2fb411cfb2f75bd",
            "c15072ebb88e466c8ebb320a108d6eda",
            "31d38028e8c44709a8014883588e4e1c",
            "fd91a2b24cff4d998346940f1d90aa0b",
            "81f501e7c31c4c898129b5a0f3e1543f",
            "b33929315b2f4cc8b7ed0fa7b5dec341",
            "1a14173af16b43a1ac2ee3fc6eadc685",
            "5165d3e62722480e9958eb8002635b6c",
            "41489a7ff586489ba808f1e74fe5eec8",
            "6cd0ef8ee0b146d791b3a1afc6323f64",
            "29ff5ef9b3454d919b0bfec7eb78d098",
            "7760e1017ce34120909045e81d9c7148"
          ]
        },
        "id": "0Vj3WCKHSKHW",
        "outputId": "cd91dd25-f859-43c7-e405-3b6079260a9e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training MNISTFlow_simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type       | Params | Mode  | In sizes | Out sizes\n",
            "--------------------------------------------------------------------\n",
            "0 | flows | ModuleList | 556 K  | train | ?        | ?        \n",
            "--------------------------------------------------------------------\n",
            "556 K     Trainable params\n",
            "0         Non-trainable params\n",
            "556 K     Total params\n",
            "2.225     Total estimated model params size (MB)\n",
            "218       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:88: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py:1303: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Scalars are not close!\n",
            "\n",
            "Expected 16.17384910583496 but got 16.181533813476562.\n",
            "Absolute difference: 0.0076847076416015625 (up to 1e-05 allowed)\n",
            "Relative difference: 0.00047513165179890223 (up to 1e-05 allowed)\n",
            "  _check_trace(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21a928b363a848fcbd0eaaa12c583be1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c15072ebb88e466c8ebb320a108d6eda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 3595 has 14.73 GiB memory in use. Of the allocated memory 13.71 GiB is allocated by PyTorch, and 927.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-9a56d035b9ac>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mflow_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"simple\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"vardeq\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiscale\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m flow_dict[\"simple\"][\"model\"], flow_dict[\"simple\"][\"result\"] = train_flow(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcreate_simple_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_vardeq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MNISTFlow_simple\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m flow_dict[\"vardeq\"][\"model\"], flow_dict[\"vardeq\"][\"result\"] = train_flow(\n",
            "\u001b[0;32m<ipython-input-11-59a0371b1721>\u001b[0m in \u001b[0;36mtrain_flow\u001b[0;34m(flow, model_name)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Test best model on validation and test set if no result has been found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         )\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected state {self.state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                     \u001b[0;31m# in automatic optimization, there can only be one optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# gradient update with accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         call._call_lightning_module_hook(\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m\"optimizer_step\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \"\"\"\n\u001b[0;32m-> 1306\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model_and_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;34m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     def _clip_gradients(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m                             )\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/precision/precision.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# unused hook - call anyway for backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_redirection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-fb94b4ac1fde>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Normalizing flows are trained by maximum likelihood => return bpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_bpd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-fb94b4ac1fde>\u001b[0m in \u001b[0;36m_get_likelihood\u001b[0;34m(self, imgs, return_ll)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mldj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mlog_pz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mlog_px\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mldj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_pz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-fb94b4ac1fde>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mldj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mldj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mldj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mldj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-77500a11d07b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, ldj, reverse, orig_img)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mz_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morig_img\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mnn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mnn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_img\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-4b939fe503c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-4b939fe503c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 11.06 MiB is free. Process 3595 has 14.73 GiB memory in use. Of the allocated memory 13.71 GiB is allocated by PyTorch, and 927.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eI5S1PClSRLM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "real_nvp_colab.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21a928b363a848fcbd0eaaa12c583be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09a5c41ae7a4444fbff61098d039678a",
              "IPY_MODEL_b772bcfd47ab4ea6bdc9e3cf63b57f71",
              "IPY_MODEL_b66c4a8f31e742e38882b689e9115d83"
            ],
            "layout": "IPY_MODEL_5a2e1eab12f84e79af31a56fb5c94564"
          }
        },
        "09a5c41ae7a4444fbff61098d039678a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_882b193bec9d4fdba13253e2a69d5e74",
            "placeholder": "​",
            "style": "IPY_MODEL_fcca76206c7747fa894e3ffea6f51095",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "b772bcfd47ab4ea6bdc9e3cf63b57f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b45bb9ff388e4f8e9ceb7e8bfc704652",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fbdca2822c748ac8c2f06bd1b0500a2",
            "value": 2
          }
        },
        "b66c4a8f31e742e38882b689e9115d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa7f5c2370eb465587608963a186b13c",
            "placeholder": "​",
            "style": "IPY_MODEL_1909d3a0a30742a0b2fb411cfb2f75bd",
            "value": " 2/2 [00:01&lt;00:00,  1.86it/s]"
          }
        },
        "5a2e1eab12f84e79af31a56fb5c94564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "882b193bec9d4fdba13253e2a69d5e74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcca76206c7747fa894e3ffea6f51095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b45bb9ff388e4f8e9ceb7e8bfc704652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fbdca2822c748ac8c2f06bd1b0500a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa7f5c2370eb465587608963a186b13c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1909d3a0a30742a0b2fb411cfb2f75bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c15072ebb88e466c8ebb320a108d6eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31d38028e8c44709a8014883588e4e1c",
              "IPY_MODEL_fd91a2b24cff4d998346940f1d90aa0b",
              "IPY_MODEL_81f501e7c31c4c898129b5a0f3e1543f"
            ],
            "layout": "IPY_MODEL_b33929315b2f4cc8b7ed0fa7b5dec341"
          }
        },
        "31d38028e8c44709a8014883588e4e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a14173af16b43a1ac2ee3fc6eadc685",
            "placeholder": "​",
            "style": "IPY_MODEL_5165d3e62722480e9958eb8002635b6c",
            "value": "Epoch 0:   0%"
          }
        },
        "fd91a2b24cff4d998346940f1d90aa0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41489a7ff586489ba808f1e74fe5eec8",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cd0ef8ee0b146d791b3a1afc6323f64",
            "value": 0
          }
        },
        "81f501e7c31c4c898129b5a0f3e1543f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29ff5ef9b3454d919b0bfec7eb78d098",
            "placeholder": "​",
            "style": "IPY_MODEL_7760e1017ce34120909045e81d9c7148",
            "value": " 0/90 [00:00&lt;?, ?it/s]"
          }
        },
        "b33929315b2f4cc8b7ed0fa7b5dec341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "1a14173af16b43a1ac2ee3fc6eadc685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5165d3e62722480e9958eb8002635b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41489a7ff586489ba808f1e74fe5eec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd0ef8ee0b146d791b3a1afc6323f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29ff5ef9b3454d919b0bfec7eb78d098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7760e1017ce34120909045e81d9c7148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}